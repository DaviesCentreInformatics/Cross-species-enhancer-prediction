{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1048645it [00:09, 112827.81it/s]\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from pyfaidx import Fasta\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.utils import shuffle, compute_class_weight\n",
    "from utils import mapping_dict, seq2kmer, one_hot, seqToWordVec, seq2kmerMatrix\n",
    "random.seed(12)\n",
    "np.random.seed(12)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Extract exons only\n",
    "gtf = pd.read_csv('/Users/callummacphillamy/PhD/Reference_Genomes/dog_10K/GCF_000002285.5_Dog10K_Boxer_Tasha_genomic.gtf',\n",
    "                  comment='#',\n",
    "                  header=None,\n",
    "                  sep='\\t',\n",
    "                  index_col=None)\n",
    "with open('/Users/callummacphillamy/PhD/Reference_Genomes/dog_10K/GCF_000002285.5_Dog10K_Boxer_Tasha_genomic.EXONS-ONLY.bed', 'w') as bed:\n",
    "    for row in gtf.itertuples():\n",
    "        if str(row[3]).lower() == 'exon':\n",
    "            assert str(row[3]).lower() == 'exon'\n",
    "            bed.write(f'{row[1]}\\t{row[4]}\\t{row[5]}\\t{row[3]}\\n')\n",
    "bed.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Subtract Exons from ChIP regions\n",
    "```shell\n",
    "bedtools subtract -a Bt_AllDatasets.consensus.MERGED.bed -b GCF_002263795.1_ARS-UCD1.2_genomic_EXONS_ONLY.bed > Bt_AllDatasets.consensus.MERGED.No-EXONS.bed\n",
    "bedtools subtract -a chip_results/Ss_AllDatasets.consensus.MERGED.bed -b GCF_000003025.6_Sscrofa11.1_genomic_EXONS_ONLY.bed > chip_results/Ss_AllDatasets.consensus.MERGED.No-EXONS.bed\n",
    "#bedtools subtract -a chip_results/Clf_H3K27ac_Villar_consensus.MERGED.bed -b GCF_014441545.1_ROS_Cfam_1.0_genomic_EXONS_ONLY.bed > Clf_H3K27ac_Villar_consensus.MERGED.No-EXONS.bed\n",
    "bedtools subtract -a chip_results/Clf_H3K27ac_Villar_consensus_0.5_reciprocal_overlap.MERGED.bed -b GCF_000002285.5_Dog10K_Boxer_Tasha_genomic.EXONS-ONLY.bed > Clf_H3K27ac_Villar_consensus.MERGED.No-EXONS.bed\n",
    "```\n",
    "\n",
    "## Subtract ChIP regions from candidate regions\n",
    "```shell\n",
    "bedtools subtract -a predictions/200bp/ARS-UCD1.2.200bp.candidate.regions.chrALL.200bp.20bp.step.tsv -b Bt_AllDatasets.consensus.MERGED.No-EXONS.bed > predictions/200bp/ARS-UCD1.2.200bp.candidate.regions.chrALL.200bp.20bp.step.No-ChIP.No.EXONS.bed\n",
    "bedtools subtract -a Sscrofa11.1.200bp.cand_regions.20bpStep.chrAll.200bp.20bpStep.bed -b chip_results/Ss_AllDatasets.consensus.MERGED.No-EXONS.bed > Sscrofa11.1.200bp.cand_regions.20bpStep.chrAll.200bp.20bpStep.NO-ChIP.No-EXONS.bed\n",
    "#bedtools subtract -a ROS_Cfam.1.candidate.regions.chrALL.200bp.20bpStep.No-Ns.bed -b Clf_H3K27ac_Villar_consensus.MERGED.No-EXONS.bed > ROS_Cfam.1.candidate.regions.chrALL.200bp.20bpStep.No-ChIP.No-EXONS.bed\n",
    "bedtools subtract -a GCF_000002285.5_Dog10K_Boxer_Tasha_genomic.NON.EXONS.RM.bed -b Clf_H3K27ac_Villar_consensus.MERGED.No-EXONS.bed > Dog10K.candidate.regions.No-ChIP.No-EXONS.bed\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59245it [00:16, 3527.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Divvy ChIP regions and/or candidate regions bed file for validation\n",
    "chip_regions = pd.read_csv('/Users/callummacphillamy/PhD/Reference_Genomes/dog_10K/Clf_H3K27ac_Villar_consensus.MERGED.No-EXONS.bed',\n",
    "                           sep='\\t',\n",
    "                           header=None,\n",
    "                           index_col=None)\n",
    "genome = Fasta('/Users/callummacphillamy/PhD/Reference_Genomes/dog_10K/GCF_000002285.5_Dog10K_Boxer_Tasha_genomic.fna')\n",
    "n_count = 0\n",
    "with open('/Users/callummacphillamy/PhD/Reference_Genomes/dog_10K/Clf_H3K27ac_Villar_consensus.MERGED.200bp.20bpStep.No-EXONS.No-Ns.bed', 'w') as bed:\n",
    "    for row in tqdm(chip_regions.itertuples()):\n",
    "        if row[3] - row[2] < 200:\n",
    "            continue\n",
    "        else:\n",
    "            len_region = row[3] - row[2]\n",
    "            #print(len_region, row[2], row[3])\n",
    "            for i in range(0, (len_region - 200 + 1), 20):\n",
    "                chro = row[1]\n",
    "                start = row[2] + i\n",
    "                stop = row[2] + i + 200\n",
    "                seq = genome[f'{chro}'][start:stop]\n",
    "                seq = str(seq).upper()\n",
    "                if 'N' in seq:\n",
    "                    n_count += 1\n",
    "                elif 'N' not in seq:\n",
    "                    bed.write(f'{chro}\\t{start}\\t{stop}\\n')\n",
    "bed.close()\n",
    "print(n_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3814452it [05:39, 11238.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create filtered candidate regions bed file for validation\n",
    "candidate_regions = pd.read_csv('/Users/callummacphillamy/PhD/Reference_Genomes/dog_10K/Dog10K.candidate.regions.No-ChIP.No-EXONS.bed',\n",
    "                                sep='\\t',\n",
    "                                header=None,\n",
    "                                index_col=None)\n",
    "n_count = 0\n",
    "n_le_200 = 0\n",
    "with open('/Users/callummacphillamy/PhD/Reference_Genomes/dog_10K/Dog10K.candidate.regions.200bp.20bpStep.No-ChIP.No.EXONS.No-Ns.bed', 'w') as bed:\n",
    "    for row in tqdm(candidate_regions.itertuples()):\n",
    "        if row[3] - row[2] < 200:\n",
    "            continue\n",
    "        else:\n",
    "            len_region = row[3] - row[2]\n",
    "            #print(len_region, row[2], row[3])\n",
    "            for i in range(0, (len_region - 200 + 1), 20):\n",
    "                chro = row[1]\n",
    "                start = row[2] + i\n",
    "                stop = row[2] + i + 200\n",
    "                seq = genome[f'{chro}'][start:stop]\n",
    "                seq = str(seq).upper()\n",
    "                if 'N' in seq:\n",
    "                    n_count += 1\n",
    "                elif 'N' not in seq:\n",
    "                    bed.write(f'{chro}\\t{start}\\t{stop}\\n')\n",
    "bed.close()\n",
    "print(n_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "### CREATE BALANCED VALIDATION SET ###\n",
    "\n",
    "# Load in candidate regions minus the ChIP-regions\n",
    "# Cattle\n",
    "candidate_regions = pd.read_csv('/Users/callummacphillamy/PhD/Reference_Genomes/canFam/ROS_Cfam.1.candidate.regions.chrALL.200bp.20bpStep.No-ChIP.No-EXONS.bed',\n",
    "                                header=None,\n",
    "                                sep='\\t',\n",
    "                                index_col=None)\n",
    "candidate_regions_idx = []\n",
    "for row in candidate_regions.itertuples():\n",
    "    if row[3] - row[2] == 200:\n",
    "        candidate_regions_idx.append(row[0])\n",
    "candidate_regions_idx = np.array(candidate_regions_idx)\n",
    "\n",
    "# Load in ChIP regions\n",
    "chip_regions = pd.read_csv('/Users/callummacphillamy/PhD/Reference_Genomes/canFam/Clf_H3K27ac_Villar_consensus.MERGED.200bp.20bpStep.No-EXONS.No-Ns.bed',\n",
    "                           header=None,\n",
    "                           index_col=None,\n",
    "                           sep='\\t')\n",
    "chip_regions_idx = np.arange(chip_regions.shape[0])\n",
    "genome = Fasta('../canFam/GCF_014441545.1_ROS_Cfam_1.0_genomic.fna')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [46:29<00:00,  2.79s/it]\n"
     ]
    }
   ],
   "source": [
    "### PERMUTATION CELL ###\n",
    "\n",
    "# Change these\n",
    "#model_h = tf.keras.models.load_model('/Users/callummacphillamy/PhD/Deeplearning_benchmark/models/trained_models/VISTA/DeepEnhancerPlus200/adam/200/hg19_VISTA_balanced_samples_DeepEnhancerPlus_200bp_0.0005_200bp.h5')\n",
    "#model_b = tf.keras.models.load_model('/Users/callummacphillamy/PhD/Deeplearning_benchmark/models/trained_models/VISTA/DeepEnhancerPlus200/adam/200/hg19.mm9_VISTA_balanced_samples_DeepEnhancerPlus_200bp_0.0005_200bp.h5')\n",
    "#model_h = DummyClassifier(strategy='uniform', random_state=12)\n",
    "#model_b = DummyClassifier(strategy='uniform', random_state=12)\n",
    "#model_h.fit(shuf_hg19_test_X, shuf_hg19_test_y)\n",
    "#model_b.fit(shuf_train_X, shuf_train_y)\n",
    "model_h = joblib.load('/Users/callummacphillamy/PhD/Deeplearning_benchmark/models/trained_models/VISTA/hg19.VISTA.svm.200bp.joblib')\n",
    "model_b = joblib.load('/Users/callummacphillamy/PhD/Deeplearning_benchmark/models/trained_models/VISTA/hg19.mm9.VISTA.svm.200bp.joblib')\n",
    "\n",
    "\n",
    "model_name = 'SVM'\n",
    "\n",
    "model_b_txt = open(f'/Users/callummacphillamy/PhD/Reference_Genomes/canFam/canFam_results/balanced_{model_name}_b.Clf.accuracy.csv', 'w')\n",
    "model_h_txt = open(f'/Users/callummacphillamy/PhD/Reference_Genomes/canFam/canFam_results/balanced_{model_name}_h.Clf.accuracy.csv', 'w')\n",
    "\n",
    "\n",
    "\n",
    "### DON'T CHANGE ###\n",
    "model_b_txt.write('iter,accuracy,f1_score,training_set,model,model_name\\n')\n",
    "model_h_txt.write('iter,accuracy,f1_score,training_set,model,model_name\\n')\n",
    "for i in tqdm(range(1000)):\n",
    "\n",
    "    # Take 500 random samples from candidate regions and from chip_regions\n",
    "    neg_test_idx = np.random.choice(candidate_regions_idx, size=500)\n",
    "    neg_test_df = candidate_regions.iloc[neg_test_idx, :3]\n",
    "    pos_test_idx = np.random.choice(chip_regions_idx, size=500)\n",
    "    pos_test_df = chip_regions.iloc[pos_test_idx, :3]\n",
    "\n",
    "    neg_X = []\n",
    "    for index in neg_test_df.itertuples():\n",
    "        chro = index[1]\n",
    "        start = index[2]\n",
    "        stop = index[3]\n",
    "        seq = genome[f'{chro}'][start:stop]\n",
    "        seq = str(seq).upper()\n",
    "        assert 'N' not in seq\n",
    "        assert len(seq) == 200, 'Length of the sequence isn\\'t 200bp'\n",
    "        #try:\n",
    "        neg_X.append(seq2kmer(seq))\n",
    "        #except ZeroDivisionError:\n",
    "        #    print(f'This sequence caused a zero division error:\\n{seq}')\n",
    "    neg_X = np.array(neg_X)\n",
    "\n",
    "    pos_X = []\n",
    "    for row in pos_test_df.itertuples():\n",
    "        chro = row[1]\n",
    "        start = row[2]\n",
    "        stop = row[3]\n",
    "        seq = genome[f'{chro}'][start:stop]\n",
    "        seq = str(seq).upper()\n",
    "        assert 'N' not in seq\n",
    "        #try:\n",
    "        pos_X.append(seq2kmer(seq))\n",
    "        #except ZeroDivisionError:\n",
    "        #    print(f'This sequence caused a zero division error:\\n{seq}')\n",
    "    pos_X = np.array(pos_X)\n",
    "\n",
    "    neg_y = np.zeros(neg_X.shape[0])\n",
    "    pos_y = np.ones(pos_X.shape[0])\n",
    "\n",
    "    test_X = np.vstack((pos_X, neg_X))\n",
    "    test_y = np.hstack((pos_y, neg_y))\n",
    "    shuf_test_X, shuf_test_y = shuffle(test_X, test_y, random_state=12)\n",
    "\n",
    "    yhat_h = model_h.predict(shuf_test_X)\n",
    "    yhat_b = model_b.predict(shuf_test_X)\n",
    "    yhat_h_score = accuracy_score(shuf_test_y, np.round(yhat_h))\n",
    "    yhat_b_score = accuracy_score(shuf_test_y, np.round(yhat_b))\n",
    "    yhat_h_f1 = f1_score(shuf_test_y, np.round(yhat_h))\n",
    "    yhat_b_f1 = f1_score(shuf_test_y, np.round(yhat_b))\n",
    "    model_b_txt.write(f'{i},{yhat_b_score},{yhat_b_f1},both,{model_name}_b,{model_name}\\n')\n",
    "    model_h_txt.write(f'{i},{yhat_h_score},{yhat_h_f1},human,{model_name}_h,{model_name}\\n')\n",
    "\n",
    "model_b_txt.close()\n",
    "model_h_txt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}