{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Process data from VISTA Enhancers\n",
    "Import the required libraries."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from utils.utils import bed_extract, gtf_annotation_extract"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the files downloaded from VISTA are in `.fasta` format rather than `.bed`\n",
    "we will need to extract the `.bed` regions from the `.fasta` records."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting bed regions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "998it [00:00, 49721.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished extracting bed regions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [00:00<00:00, 816763.98it/s]\n"
     ]
    }
   ],
   "source": [
    "### HUMAN ###\n",
    "# This cell will extract the bed coordinates from the VISTA hg19 fasta file\n",
    "# and write it into a bed file.\n",
    "in_fa = '/Users/callummacphillamy/PhD/Reference_Genomes/hg19/hg19.VISTA.enhancers.fa'\n",
    "beds = []\n",
    "print('Extracting bed regions')\n",
    "for record in tqdm(SeqIO.parse(in_fa, 'fasta')):\n",
    "    rec = re.split('[|:-]', record.name)\n",
    "    beds.append((rec[1:]))\n",
    "print('Finished extracting bed regions')\n",
    "\n",
    "with open('/Users/callummacphillamy/PhD/Reference_Genomes/hg19/hg19.VISTA.enhancers.bed', 'w') as bed:\n",
    "\n",
    "    for i in tqdm(beds):\n",
    "        bed.write(f'{i[0]}\\t{i[1]}\\t{i[2]}\\tenhancer\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "hg19 = pd.read_csv('../../Reference_Genomes/hg19/hg19.Ensembl.annotations.sorted.bed',\n",
    "                   sep='\\t',\n",
    "                   header=None,\n",
    "                   index_col=None)\n",
    "enhancers = pd.read_csv('../../Reference_Genomes/hg19/hg19.VISTA.enhancers.sorted.bed',\n",
    "                        sep='\\t',\n",
    "                        header=None,\n",
    "                        index_col = None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2612761it [01:33, 28070.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "intron_en = 0\n",
    "intron_enhancers = open('../../Reference_Genomes/hg19/hg19.VISTA.intron.enhancers.bed', 'w')\n",
    "for row in tqdm(hg19.itertuples()):\n",
    "    #print(row)\n",
    "    if row[4] == 'gene':\n",
    "        for en in enhancers.itertuples():\n",
    "            chrom = row[1]\n",
    "            gene_start = row[2]\n",
    "            gene_stop = row[3]\n",
    "            en_chrom = en[1]\n",
    "            en_start = en[2]\n",
    "            en_stop = en[3]\n",
    "            if chrom == en_chrom:\n",
    "                if en_start > gene_start and en_stop < gene_stop:\n",
    "                    #intron_enhancers.write(f'{en_chrom}\\t{en_start}\\t{en_stop}\\n')\n",
    "                    intron_en += 1\n",
    "\n",
    "print(intron_en)\n",
    "intron_enhancers.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "656it [00:00, 32528.21it/s]\n",
      "100%|██████████| 656/656 [00:00<00:00, 349703.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting bed regions\n",
      "Finished extracting bed regions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### MOUSE ###\n",
    "\n",
    "in_fa = '../data/VISTA/mm9/originals/mm9.VISTA.enhancers.fa'\n",
    "beds = []\n",
    "print('Extracting bed regions')\n",
    "for record in tqdm(SeqIO.parse(in_fa, 'fasta')):\n",
    "    rec = re.split('[|:-]', record.name)\n",
    "    beds.append((rec[1:]))\n",
    "print('Finished extracting bed regions')\n",
    "\n",
    "with open('../data/VISTA/mm9/originals/mm9.VISTA.enhancers.bed', 'w') as bed:\n",
    "\n",
    "    for i in tqdm(beds):\n",
    "        if not re.match('chr[XYxy]', i[0]):\n",
    "            bed.write(f'{i[0]}\\t{i[1]}\\t{i[2]}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then want to sort the enhancers such that chr1, chr2, ... chrN.\n",
    "`cat hg19.VISTA.enhancers.bed | sort -V > sorted.hg19.VISTA.enhancers.bed`\n",
    "\n",
    "Next, we filter the enhancer bed file to remove the autosomes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1 ID: chr1\n",
      "Name: chr1\n",
      "Description: chr1\n",
      "Number of features: 0\n",
      "Seq('NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...NNN')\n"
     ]
    }
   ],
   "source": [
    "### HUMAN ###\n",
    "hg19 = SeqIO.to_dict(SeqIO.parse\n",
    "                     ('/Users/callummacphillamy/PhD/Reference_Genomes/hg19/hg19'\n",
    "                      '.fa', 'fasta'))\n",
    "\n",
    "auto_hg19 = {}\n",
    "autos = [f'chr{i}' for i in range(1,23)]\n",
    "for k, v in hg19.items():\n",
    "    if k in autos:\n",
    "        auto_hg19[f'{k}'] = v\n",
    "gen = open('/Users/callummacphillamy/PhD/Reference_Genomes/hg19/hg19.autos'\n",
    "           '.fa', mode='w')\n",
    "for k, v in auto_hg19.items():\n",
    "    gen.write(f'>{k}\\n{v.seq}\\n')\n",
    "gen.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "### MOUSE ###\n",
    "mm9 = SeqIO.to_dict(SeqIO.parse\n",
    "                     ('/Users/callummacphillamy/PhD/Reference_Genomes/mm9/mm9'\n",
    "                      '.fa',\n",
    "                      'fasta'))\n",
    "\n",
    "auto_mm9 = {}\n",
    "autos = [f'chr{i}' for i in range(1,21)]\n",
    "for k, v in mm9.items():\n",
    "    if k in autos:\n",
    "        auto_mm9[f'{k}'] = v\n",
    "gen = open('/Users/callummacphillamy/PhD/Reference_Genomes/mm9/mm9.autos.fa',\n",
    "           mode='w')\n",
    "for k, v in auto_mm9.items():\n",
    "    gen.write(f'>{k}\\n{v.seq}\\n')\n",
    "gen.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "985it [00:05, 195.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chromosome\tGC content (%)\n",
      "chr1\t37.7294843329598\n",
      "chr2\t39.41725088246835\n",
      "chr3\t39.04775181276182\n",
      "chr4\t37.54905697218094\n",
      "chr5\t38.81296083039098\n",
      "chr6\t38.749778825730175\n",
      "chr7\t39.78206666220389\n",
      "chr8\t39.22180001312071\n",
      "chr9\t35.15208903889602\n",
      "chr10\t40.290089595991205\n",
      "chr11\t40.37200397053428\n",
      "chr12\t39.7843041370464\n",
      "chr13\t31.976654520724594\n",
      "chr14\t33.62760473868821\n",
      "chr15\t33.624793663193415\n",
      "chr16\t39.103673937330115\n",
      "chr17\t43.63348034939499\n",
      "chr18\t38.04226808813753\n",
      "chr20\t41.66128260425301\n",
      "chr19\t45.64495891972301\n",
      "chr22\t32.63884738835916\n",
      "chr21\t29.783844323782546\n",
      "\n",
      "Average GC content of hg19 autosomes: \t 37.983911163994144\n",
      "\n",
      "           Lengths  GC content  Percentage of Ns  Molecular weight\n",
      "count   985.000000  985.000000             985.0      9.850000e+02\n",
      "mean   2084.502538   42.778536               0.0      6.439361e+05\n",
      "std    1169.124057    7.487879               0.0      3.611484e+05\n",
      "min     428.000000   26.410027               0.0      1.320661e+05\n",
      "25%    1259.000000   36.982846               0.0      3.895556e+05\n",
      "50%    1680.000000   41.290323               0.0      5.198224e+05\n",
      "75%    2768.000000   47.379091               0.0      8.541973e+05\n",
      "max    8061.000000   65.652174               0.0      2.496018e+06\n"
     ]
    }
   ],
   "source": [
    "### HUMAN ###\n",
    "\n",
    "from utils.utils import fa_stats\n",
    "from Bio.SeqUtils import GC\n",
    "stats = fa_stats('../data/VISTA/hg19/originals/hg19.VISTA.enhancers.noXY.fa')\n",
    "autos_hg19 = SeqIO.to_dict(SeqIO.parse\n",
    "                     ('/Users/callummacphillamy/PhD/Reference_Genomes/hg19'\n",
    "                      '/hg19.autos'\n",
    "                      '.fa', 'fasta'))\n",
    "\n",
    "gc_content = []\n",
    "print('Chromosome\\tGC content (%)')\n",
    "for k, v in autos_hg19.items():\n",
    "    gc_content.append(GC(v.seq))\n",
    "    print(f'{k}\\t{GC(v.seq)}')\n",
    "gc_content = np.array(gc_content)\n",
    "print(f'\\nAverage GC content of hg19 autosomes: \\t {np.sum(gc_content)/gc_content.shape[0]}\\n')\n",
    "\n",
    "enh_stats_df = pd.DataFrame.from_dict(stats)\n",
    "\n",
    "print(enh_stats_df.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "653it [00:04, 154.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chromosome\tGC content (%)\n",
      "chr1\t39.94467376911652\n",
      "chr2\t41.305718392513256\n",
      "chr3\t39.637652264226446\n",
      "chr4\t41.2821020763847\n",
      "chr5\t41.1918507071115\n",
      "chr6\t40.52969762904009\n",
      "chr7\t40.03539810406787\n",
      "chr8\t40.13509801522437\n",
      "chr9\t41.55822118690122\n",
      "chr10\t40.39910839989352\n",
      "chr11\t42.69902374068004\n",
      "chr12\t40.44685884662173\n",
      "chr13\t40.2600864525043\n",
      "chr14\t39.987965480756465\n",
      "chr15\t40.72388191527059\n",
      "chr16\t39.55810541486577\n",
      "chr17\t41.18025434182576\n",
      "chr18\t39.988956510183186\n",
      "chr19\t40.50337262478842\n",
      "Average GC content of mm9 autosomes:\t40.59831715115662\n",
      "           Lengths  GC content  Percentage of Ns  Molecular weight\n",
      "count   653.000000  653.000000             653.0      6.530000e+02\n",
      "mean   2533.272588   47.199045               0.0      7.824816e+05\n",
      "std    1165.620742    5.210994               0.0      3.600263e+05\n",
      "min     330.000000   32.624662               0.0      1.027655e+05\n",
      "25%    1597.000000   43.736264               0.0      4.932034e+05\n",
      "50%    2503.000000   47.200805               0.0      7.734455e+05\n",
      "75%    3243.000000   50.842886               0.0      1.000857e+06\n",
      "max    6729.000000   61.699651               0.0      2.079163e+06\n"
     ]
    }
   ],
   "source": [
    "### MOUSE ###\n",
    "from utils.utils import fa_stats\n",
    "from Bio.SeqUtils import GC\n",
    "\n",
    "stats = fa_stats('../data/VISTA/mm9/originals/mm9.VISTA.enhancers.noXY.fa')\n",
    "autos_mm9 = SeqIO.to_dict(SeqIO.parse\n",
    "                          ('/Users/callummacphillamy/PhD/Reference_Genomes'\n",
    "                           '/mm9/mm9.autos.fa','fasta'))\n",
    "gc_content=[]\n",
    "print('Chromosome\\tGC content (%)')\n",
    "for k, v in autos_mm9.items():\n",
    "    gc_content.append(GC(v.seq))\n",
    "    print(f'{k}\\t{GC(v.seq)}')\n",
    "gc_content = np.array(gc_content)\n",
    "print(f'Average GC content of mm9 autosomes:\\t{np.sum(gc_content)/gc_content.shape[0]}')\n",
    "mm9_stats_df = pd.DataFrame.from_dict(stats)\n",
    "print(mm9_stats_df.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/callummacphillamy/anaconda3/envs/pred-comp/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<AxesSubplot:xlabel='GC content', ylabel='Density'>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "gc = enh_stats_df.iloc[:, 1]\n",
    "sns.set_style('darkgrid')\n",
    "sns.distplot(gc, bins=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "985it [00:00, 1357.25it/s]\n",
      "985it [00:00, 2176.02it/s]\n",
      "653it [00:00, 1068.49it/s]\n",
      "653it [00:00, 1940.94it/s]\n"
     ]
    }
   ],
   "source": [
    "### HUMAN ###\n",
    "# Read in bed file and generate positive windows.\n",
    "bed = pd.read_csv('../data/VISTA/hg19/originals/hg19.VISTA.enhancers.noXY.bed',\n",
    "                  header=None,\n",
    "                  index_col=None,\n",
    "                  sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "985it [00:00, 1297.00it/s]\n",
      "985it [00:00, 2924.37it/s]\n",
      "653it [00:00, 980.92it/s] \n",
      "653it [00:00, 1614.50it/s]\n"
     ]
    }
   ],
   "source": [
    "windows = [1000,2000] #, 4000, 8000]\n",
    "species = ['hg19', 'mm9']\n",
    "#windows = [500]\n",
    "for s in species:\n",
    "    for w in windows:\n",
    "        bed_extract(in_bed=f'../data/VISTA/{s}/originals/{s}.VISTA.enhancers'\n",
    "                           '.noXY.bed',\n",
    "            outfile=f'../data/VISTA/{s}/pos_bed/{s}.VISTA.enhancers.noXY'\n",
    "                    f'.{w}bp.bed',\n",
    "            window=w,\n",
    "            step=1,\n",
    "            label='enhancer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "653it [00:00, 722.30it/s]\n",
      "653it [00:00, 773.96it/s] \n",
      "653it [00:00, 1013.36it/s]\n",
      "653it [00:00, 1412.81it/s]\n",
      "653it [00:00, 1977.72it/s]\n",
      "653it [00:00, 11580.89it/s]\n",
      "653it [00:00, 392952.73it/s]\n"
     ]
    }
   ],
   "source": [
    "### MOUSE ###\n",
    "bed = pd.read_csv('../data/VISTA/mm9/originals/mm9.VISTA.enhancers.noXY.bed',\n",
    "                  header=None,\n",
    "                  index_col=None,\n",
    "                  sep='\\t')\n",
    "\n",
    "windows = [200, 400, 1000, 1500, 2000, 4000, 8000]\n",
    "#windows = [500]\n",
    "for w in windows:\n",
    "    bed_extract(in_bed='../data/VISTA/mm9/originals/mm9.VISTA.enhancers.noXY'\n",
    "                       '.bed',\n",
    "            outfile=f'../data/VISTA/mm9/pos_bed/mm9.VISTA.enhancers.noXY'\n",
    "                    f'.{w}bp.bed',\n",
    "            window=w,\n",
    "            step=1,\n",
    "            label='enhancer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above cell will generate a series of files based on the sorted VISTA\n",
    "enhancers file.\n",
    "\n",
    "If the original enhancer region is shorter than the desired\n",
    "window size then it will take the window size (e.g. 200bp) centered around the\n",
    "midpoint of the original enhancer region.\n",
    "\n",
    "Next, we want to find the promoter regions for the protein coding genes. This\n",
    " may need some tweaking, but currently I take a 2kb region centered around\n",
    " the start of the protein coding gene."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in genome annotation file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/callummacphillamy/anaconda3/envs/pred-comp/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3169: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "31164it [00:00, 311618.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding protein-coding regions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2612761it [00:05, 459838.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of protein coding genes in the genome: 20327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Find promoter regions for protein-coding genes.\n",
    "# CrepHAN say that they define the promoter region as a 2kb region centered\n",
    "# around the TSS of protein-coding genes.\n",
    "print(f'Reading in genome annotation file.')\n",
    "genes = pd.read_csv('../data/VISTA/hg19/originals/Homo_sapiens.GRCh37.87.chr'\n",
    "                    '.gtf',\n",
    "                    header=None,\n",
    "                    index_col=None,\n",
    "                    sep='\\t',\n",
    "                    comment='#')\n",
    "count = 0\n",
    "protein_coding_idx = []\n",
    "print('Finding protein-coding regions.')\n",
    "for i in tqdm(genes.itertuples()):\n",
    "    if re.match('gene', i[3]):\n",
    "        #print(i)\n",
    "        gene = re.split(';',i[9])\n",
    "        if 'protein_coding' in gene[-2]:\n",
    "            protein_coding_idx.append(i[0])\n",
    "            count += 1\n",
    "        #break\n",
    "print(f'Number of protein coding genes in the genome: {count}')\n",
    "\n",
    "protein_df = genes.iloc[protein_coding_idx, :]\n",
    "\n",
    "protein_df.reset_index(drop=True,\n",
    "                       inplace=True)\n",
    "print('Writing promoter regions to bed file.')\n",
    "with open('../data/VISTA/hg19/originals/hg19.VISTA.promoter_regions.bed', 'w') \\\n",
    "        as bed:\n",
    "    for i in protein_df.itertuples():\n",
    "        if re.match('[+]', i[7]):\n",
    "            bed.write(f'chr{i[1]}\\t{i[4]-1000}\\t{i[4]+1000}\\tpromoter_region\\n')\n",
    "        elif re.match('[-]', i[7]):\n",
    "            assert i[7] == '-', 'Somthing went wrong'\n",
    "            bed.write(f'chr{i[1]}\\t{i[5]-1000}\\t{i[5]+1000}\\tpromoter_region\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in genome annotation file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43149it [00:00, 431471.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding protein-coding regions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1541720it [00:02, 560324.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of protein coding genes in the genome: 21567\n",
      "Writing promoter regions to bed file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Reading in genome annotation file.')\n",
    "genes = pd.read_csv('../data/VISTA/mm9/originals/gencode.vM1.annotation.gtf',\n",
    "                    header=None,\n",
    "                    index_col=None,\n",
    "                    sep='\\t',\n",
    "                    comment='#')\n",
    "count = 0\n",
    "protein_coding_idx = []\n",
    "print('Finding protein-coding regions.')\n",
    "for i in tqdm(genes.itertuples()):\n",
    "    if re.match('gene', i[3]):\n",
    "        #print(i)\n",
    "        gene = re.split(';',i[9])\n",
    "        gene_type = gene[2]\n",
    "        gene_status = gene[3]\n",
    "        assert 'gene_type' in gene_type, 'Something went wrong. There is no ' \\\n",
    "                                         '\"gene_type\" in `gene_type`.'\n",
    "        assert 'gene_status' in gene_status, 'No \"gene_status\" in ' \\\n",
    "                                             '`gene_status`.'\n",
    "        if 'protein_coding' in gene_type and 'KNOWN' in gene_status:\n",
    "            protein_coding_idx.append(i[0])\n",
    "            count += 1\n",
    "\n",
    "print(f'Number of protein coding genes in the genome: {count}')\n",
    "\n",
    "protein_df = genes.iloc[protein_coding_idx, :]\n",
    "\n",
    "protein_df.reset_index(drop=True,\n",
    "                       inplace=True)\n",
    "print('Writing promoter regions to bed file.')\n",
    "with open('../data/VISTA/mm9/originals/mm9.VISTA.promoter_regions.bed', 'w') \\\n",
    "        as bed:\n",
    "    for i in protein_df.itertuples():\n",
    "        if re.match('[+]', i[7]):\n",
    "            assert i[7] == '+', 'Something went wrong.'\n",
    "            bed.write(f'{i[1]}\\t{i[4]-1000}\\t{i[4]+1000}\\tpromoter_region\\n')\n",
    "        elif re.match('[-]', i[7]):\n",
    "            assert i[7] == '-', 'Somthing went wrong'\n",
    "            bed.write(f'{i[1]}\\t{i[5]-1000}\\t{i[5]+1000}\\tpromoter_region\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see the number of protein-coding genes is ~20,000 which sounds\n",
    "pretty good for the human genome.\n",
    "\n",
    "Next, we need to reformat the `.gtf` file to make it compatible with our\n",
    "other annotation files and `bedtools complement`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in annotation file ../data/VISTA/hg19/originals/Homo_sapiens.GRCh37.87.chr.gtf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/callummacphillamy/anaconda3/envs/pred-comp/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3361: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "43155it [00:00, 431532.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reformatted annotations to ../data/VISTA/hg19/originals/hg19.Ensembl.annotations.bed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2612761it [00:04, 568648.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Finished. Saved to ../data/VISTA/hg19/originals/hg19.Ensembl.annotations.bed'"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HUMAN ###\n",
    "gtf_annotation_extract('../data/VISTA/hg19/originals/Homo_sapiens.GRCh37.87.chr'\n",
    "                       '.gtf',\n",
    "                       '../data/VISTA/hg19/originals/hg19.Ensembl.annotations'\n",
    "                       '.bed')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in annotation file ../data/VISTA/mm9/originals/gencode.vM1.annotation.gtf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111980it [00:00, 562379.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reformatted annotations to ../data/VISTA/mm9/originals/mm9.GENCODE.annotations.bed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1541720it [00:02, 571947.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Finished. Saved to ../data/VISTA/mm9/originals/mm9.GENCODE.annotations.bed'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MOUSE ###\n",
    "gtf_annotation_extract('../data/VISTA/mm9/originals/gencode.vM1.annotation'\n",
    "                       '.gtf',\n",
    "                       '../data/VISTA/mm9/originals/mm9.GENCODE.annotations'\n",
    "                       '.bed',\n",
    "                       append_chr=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "bl = pd.read_csv('../data/VISTA/mm9/originals/mm9-blacklist.bed',\n",
    "                 header=None,\n",
    "                 sep='\\t',\n",
    "                 index_col=None)\n",
    "new_bl = open('../data/VISTA/mm9/originals/mm9.ENCODE.blacklist.v1.bed', 'w')\n",
    "for i in bl.itertuples():\n",
    "    #print(bl[1], bl[2])\n",
    "    new_bl.write(f'{i[1]}\\t{i[2]}\\t{i[3]}\\tENCODE_blacklist_v1\\n')\n",
    "new_bl.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then want to create bed files that represent all annotated regions of the\n",
    "genome. This requires us to combine the genome annotations, enhancers of the\n",
    "desired window size, the blacklisted regions and the promoter regions.\n",
    "\n",
    "```shell\n",
    "x=(200 400 1000 1500 2000 4000 8000)\n",
    "for i in ${x[@]}\n",
    "do\n",
    "  cat hg19.ENCODE.blacklist.bed hg19.VISTA.promoter_regions.bed hg19\n",
    "  .annotations.bed sorted.hg19.VISTA.enhancers.${i}bp.bed | sort -V > hg19\n",
    "  .VISTA.annotated.regions.${i}bp.bed\n",
    "done\n",
    "```\n",
    "\n",
    "Create the non-genic regions for each window size.\n",
    "```shell\n",
    "x=(200 400 1000 1500 2000 4000 8000)\n",
    "for i in ${x[@]}\n",
    "do\n",
    "  bedtools complement -i hg19.VISTA.annotated.regions.${i}bp.bed -g sorted\n",
    "  .hg19.chrom.sizes > hg19.non-genic.regions.${i}bp.bed\n",
    "done\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32534it [00:01, 18589.37it/s]\n",
      "32526it [00:00, 38463.63it/s]\n",
      "28342it [00:01, 15321.47it/s]\n",
      "28340it [00:00, 30091.83it/s]\n"
     ]
    }
   ],
   "source": [
    "### HUMAN ###\n",
    "from utils.utils import neg_bed_extract\n",
    "for s in species:\n",
    "    for w in windows:\n",
    "        neg_bed_extract(f'../data/VISTA/{s}/neg_bed/{s}.VISTA.non-genic'\n",
    "                        f'.regions'\n",
    "                    f'.{w}bp.bed',\n",
    "                    f'../data/VISTA/{s}/neg_bed/{s}.VISTA.non_enhancers.{w}bp'\n",
    "                    f'.bed',\n",
    "                    window=w,\n",
    "                    step=(w//2),\n",
    "                    label='non_enhancer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28343it [00:09, 2940.72it/s]\n",
      "28343it [00:04, 5756.09it/s]\n",
      "28342it [00:02, 14134.91it/s]\n",
      "28342it [00:01, 22998.56it/s]\n",
      "28340it [00:00, 30169.10it/s]\n",
      "28327it [00:00, 59425.37it/s]\n",
      "28299it [00:00, 112904.74it/s]\n"
     ]
    }
   ],
   "source": [
    "### MOUSE ###\n",
    "windows = [200, 400, 1000, 1500, 2000, 4000, 8000]\n",
    "from utils.utils import neg_bed_extract\n",
    "for w in windows:\n",
    "    neg_bed_extract(f'../data/VISTA/mm9/neg_bed/mm9.VISTA.non-genic'\n",
    "                    f'.regions.{w}bp.bed',\n",
    "                    f'../data/VISTA/mm9/neg_bed/mm9.VISTA.non_enhancers.{w}bp'\n",
    "                    f'.bed',\n",
    "                    window=w,\n",
    "                    step=(w//2),\n",
    "                    label='non_enhancer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## SKIP THIS STEP ##\n",
    "# Split data so that there is no overlap between examples in the training,\n",
    "# validation and testing sets.\n",
    "from sklearn.utils import shuffle\n",
    "hg19 = [f'chr{i}' for i in range(1,23)]\n",
    "\n",
    "# Shuffle the chromosomes\n",
    "shuf_hg19 = shuffle(hg19, random_state=12)\n",
    "\n",
    "# Create training, validation and testing splits. 70-20-10 split\n",
    "train_chrs = shuf_hg19[:int(len(shuf_hg19)*0.7)]\n",
    "val_chrs = shuf_hg19[int(len(shuf_hg19)*0.7):int(len(shuf_hg19)*0.9)]\n",
    "test_chrs = shuf_hg19[int(len(shuf_hg19)*0.9):]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in 1000bp positive regions\n",
      "Deduplicating dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating index of 1090891 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n",
      "Writing training, validation and testing sets to files for positive 1000bp to files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "763623it [00:01, 696549.36it/s]\n",
      "218178it [00:00, 781478.32it/s]\n",
      "109090it [00:00, 709990.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in 1000bp positive regions\n",
      "Deduplicating dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating index of 1009532 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n",
      "Writing training, validation and testing sets to files for positive 1000bp to files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "706672it [00:00, 738534.81it/s]\n",
      "201906it [00:00, 638585.57it/s]\n",
      "100954it [00:00, 653720.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in 2000bp positive regions\n",
      "Deduplicating dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58524it [00:00, 585158.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating index of 491013 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n",
      "Writing training, validation and testing sets to files for positive 2000bp to files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "343709it [00:00, 698918.15it/s]\n",
      "98202it [00:00, 638998.80it/s]\n",
      "49102it [00:00, 652136.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in 2000bp positive regions\n",
      "Deduplicating dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59333it [00:00, 593305.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating index of 501482 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n",
      "Writing training, validation and testing sets to files for positive 2000bp to files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "351037it [00:00, 683453.92it/s]\n",
      "100296it [00:00, 663026.76it/s]\n",
      "50149it [00:00, 622179.29it/s]\n"
     ]
    }
   ],
   "source": [
    "### HUMAN ###\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Read in bed file for all positive examples\n",
    "windows = [1000, 2000] #1500, 2000, 4000, 8000]\n",
    "for w in windows:\n",
    "    for s in species:\n",
    "        print(f'Reading in {w}bp positive regions')\n",
    "        pos_df = pd.read_csv(f'../data/VISTA/{s}/pos_bed/{s}.VISTA.enhancers'\n",
    "                         f'.noXY.{w}bp.bed',\n",
    "                     header=None,\n",
    "                     index_col=None,\n",
    "                     sep='\\t')\n",
    "\n",
    "        # Remove any duplicated regions\n",
    "        print('Deduplicating dataframe')\n",
    "        pos_dedup = pos_df.drop_duplicates()\n",
    "\n",
    "        print(f'Generating index of {pos_dedup.shape[0]} examples\\n')\n",
    "        pos_df_idx = np.arange(pos_dedup.shape[0])\n",
    "        print(f'Shuffling and splitting...')\n",
    "        shuf_idx = shuffle(pos_df_idx, random_state=12)\n",
    "\n",
    "        train_idx = shuf_idx[:int(len(shuf_idx)*0.7)]\n",
    "        val_idx = shuf_idx[int(len(shuf_idx)*0.7):int(len(shuf_idx)*0.9)]\n",
    "        test_idx = shuf_idx[int(len(shuf_idx)*0.9):]\n",
    "\n",
    "        train_df = pos_dedup.iloc[train_idx, :]\n",
    "        val_df = pos_dedup.iloc[val_idx, :]\n",
    "        test_df = pos_dedup.iloc[test_idx, :]\n",
    "\n",
    "        print('Writing to files')\n",
    "        train_bed = open(f'../data/VISTA/{s}/pos_bed/{s}.VISTA.enhancers.noXY'\n",
    "                     f'.{w}bp'\n",
    "                 f'.train.bed', 'w')\n",
    "        val_bed = open(f'../data/VISTA/{s}/pos_bed/{s}.VISTA.enhancers.noXY'\n",
    "                       f'.{w}bp'\n",
    "                 f'.val.bed', 'w')\n",
    "        test_bed = open(f'../data/VISTA/{s}/pos_bed/{s}.VISTA.enhancers.noXY'\n",
    "                        f'.{w}bp'\n",
    "                 f'.test.bed', 'w')\n",
    "        print(f'Writing training, validation and testing sets to files for '\n",
    "          f'positive {w}bp to files.')\n",
    "        for i in tqdm(train_df.itertuples()):\n",
    "            train_bed.write(f'{i[1]}\\t{i[2]}\\t{i[3]}\\n')\n",
    "        for i in tqdm(val_df.itertuples()):\n",
    "            val_bed.write(f'{i[1]}\\t{i[2]}\\t{i[3]}\\n')\n",
    "        for i in tqdm(test_df.itertuples()):\n",
    "            test_bed.write(f'{i[1]}\\t{i[2]}\\t{i[3]}\\n')\n",
    "        train_bed.close()\n",
    "        val_bed.close()\n",
    "        test_bed.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in 200bp positive regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 1515459 examples\n",
      "\n",
      "Shuffling and splitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61688it [00:00, 616855.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to files\n",
      "Writing training, validation and testing sets to files for positive 200bp to files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1060821it [00:01, 768405.07it/s]\n",
      "303092it [00:00, 805151.91it/s]\n",
      "151546it [00:00, 652883.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in 400bp positive regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 1386729 examples\n",
      "\n",
      "Shuffling and splitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51125it [00:00, 511218.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to files\n",
      "Writing training, validation and testing sets to files for positive 400bp to files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "970710it [00:01, 672640.76it/s]\n",
      "277346it [00:00, 661617.32it/s]\n",
      "138673it [00:00, 668915.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in 1000bp positive regions\n",
      "Deduplicating dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58904it [00:00, 589018.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating index of 1009532 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n",
      "Writing training, validation and testing sets to files for positive 1000bp to files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "706672it [00:01, 647769.69it/s]\n",
      "201906it [00:00, 614661.75it/s]\n",
      "100954it [00:00, 709197.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in 1500bp positive regions\n",
      "Deduplicating dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65207it [00:00, 652051.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating index of 733558 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n",
      "Writing training, validation and testing sets to files for positive 1500bp to files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "513490it [00:00, 750805.34it/s]\n",
      "146712it [00:00, 720193.26it/s]\n",
      "73356it [00:00, 677903.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in 2000bp positive regions\n",
      "Deduplicating dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64846it [00:00, 648435.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating index of 501482 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n",
      "Writing training, validation and testing sets to files for positive 2000bp to files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "351037it [00:00, 726186.35it/s]\n",
      "100296it [00:00, 736835.50it/s]\n",
      "50149it [00:00, 692569.07it/s]\n",
      "39754it [00:00, 741612.12it/s]\n",
      "11358it [00:00, 578928.94it/s]\n",
      "5680it [00:00, 714995.40it/s]\n",
      "457it [00:00, 444526.19it/s]\n",
      "130it [00:00, 485538.31it/s]\n",
      "66it [00:00, 532353.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in 4000bp positive regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 56792 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n",
      "Writing training, validation and testing sets to files for positive 4000bp to files.\n",
      "Reading in 8000bp positive regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 653 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n",
      "Writing training, validation and testing sets to files for positive 8000bp to files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### MOUSE ###\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Read in bed file for all positive examples\n",
    "windows = [200, 400, 1000, 1500, 2000, 4000, 8000]\n",
    "for w in windows:\n",
    "    print(f'Reading in {w}bp positive regions')\n",
    "    pos_df = pd.read_csv(f'../data/VISTA/mm9/pos_bed/mm9.VISTA.enhancers'\n",
    "                         f'.noXY.{w}bp.bed',\n",
    "                     header=None,\n",
    "                     index_col=None,\n",
    "                     sep='\\t')\n",
    "\n",
    "    # Remove any duplicated regions\n",
    "    print('Deduplicating dataframe')\n",
    "    pos_dedup = pos_df.drop_duplicates()\n",
    "\n",
    "    print(f'Generating index of {pos_dedup.shape[0]} examples\\n')\n",
    "    pos_df_idx = np.arange(pos_dedup.shape[0])\n",
    "    print(f'Shuffling and splitting...')\n",
    "    shuf_idx = shuffle(pos_df_idx, random_state=12)\n",
    "\n",
    "    train_idx = shuf_idx[:int(len(shuf_idx)*0.7)]\n",
    "    val_idx = shuf_idx[int(len(shuf_idx)*0.7):int(len(shuf_idx)*0.9)]\n",
    "    test_idx = shuf_idx[int(len(shuf_idx)*0.9):]\n",
    "\n",
    "    train_df = pos_dedup.iloc[train_idx, :]\n",
    "    val_df = pos_dedup.iloc[val_idx, :]\n",
    "    test_df = pos_dedup.iloc[test_idx, :]\n",
    "\n",
    "    print('Writing to files')\n",
    "    train_bed = open(f'../data/VISTA/mm9/pos_bed/mm9.VISTA.enhancers.noXY'\n",
    "                     f'.{w}bp'\n",
    "                 f'.train.bed', 'w')\n",
    "    val_bed = open(f'../data/VISTA/mm9/pos_bed/mm9.VISTA.enhancers.noXY.{w}bp'\n",
    "                 f'.val.bed', 'w')\n",
    "    test_bed = open(f'../data/VISTA/mm9/pos_bed/mm9.VISTA.enhancers.noXY.{w}bp'\n",
    "                 f'.test.bed', 'w')\n",
    "    print(f'Writing training, validation and testing sets to files for '\n",
    "          f'positive {w}bp to files.')\n",
    "    for i in tqdm(train_df.itertuples()):\n",
    "        train_bed.write(f'{i[1]}\\t{i[2]}\\t{i[3]}\\n')\n",
    "    for i in tqdm(val_df.itertuples()):\n",
    "        val_bed.write(f'{i[1]}\\t{i[2]}\\t{i[3]}\\n')\n",
    "    for i in tqdm(test_df.itertuples()):\n",
    "        test_bed.write(f'{i[1]}\\t{i[2]}\\t{i[3]}\\n')\n",
    "    train_bed.close()\n",
    "    val_bed.close()\n",
    "    test_bed.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in negative regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 3046199 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n",
      "Reading in negative regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 3251292 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:18<00:18, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in negative regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 1500630 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n",
      "Reading in negative regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 1605625 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:26<00:00, 13.45s/it]\n"
     ]
    }
   ],
   "source": [
    "### HUMAN ###\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "windows = [1000,2000] #[200, 400, 1000, 1500, 2000, 4000, 8000]\n",
    "# Read in bed file for all negative examples\n",
    "for w in tqdm(windows):\n",
    "    for s in species:\n",
    "        print(f'Reading in negative regions')\n",
    "        neg_df = pd.read_csv(f'../data/VISTA/{s}/neg_bed/{s}.VISTA'\n",
    "                         f'.non_enhancers.{w}bp.bed',\n",
    "                     header=None,\n",
    "                     index_col=None,\n",
    "                     sep='\\t')\n",
    "        print(\"Deduplicating dataframe\")\n",
    "        neg_dedup = neg_df.drop_duplicates()\n",
    "\n",
    "        print(f'Generating index of {neg_dedup.shape[0]} examples\\n')\n",
    "        neg_df_idx = np.arange(neg_dedup.shape[0])\n",
    "        print(f'Shuffling and splitting...')\n",
    "\n",
    "        shuf_idx = shuffle(neg_df_idx, random_state=12)\n",
    "\n",
    "        train_idx = shuf_idx[:int(len(shuf_idx)*0.7)]\n",
    "        val_idx = shuf_idx[int(len(shuf_idx)*0.7):int(len(shuf_idx)*0.9)]\n",
    "        test_idx = shuf_idx[int(len(shuf_idx)*0.9):]\n",
    "\n",
    "        train_df = neg_dedup.iloc[train_idx, :]\n",
    "        val_df = neg_dedup.iloc[val_idx, :]\n",
    "        test_df = neg_dedup.iloc[test_idx, :]\n",
    "\n",
    "        print('Writing to files')\n",
    "        train_bed = open(f'../data/VISTA/{s}/neg_bed/{s}.VISTA.non_enhancers'\n",
    "                     f'.{w}bp'\n",
    "                 f'.train.bed', 'w')\n",
    "        val_bed = open(f'../data/VISTA/{s}/neg_bed/{s}.VISTA.non_enhancers'\n",
    "                   f'.{w}bp'\n",
    "                 f'.val.bed', 'w')\n",
    "        test_bed = open(f'../data/VISTA/{s}/neg_bed/{s}.VISTA.non_enhancers'\n",
    "                    f'.{w}bp'\n",
    "                 f'.test.bed', 'w')\n",
    "        for i in train_df.itertuples():\n",
    "            if re.match('chr[0-9]', i[1]):\n",
    "                train_bed.write(f'{i[1]}\\t{i[2]}\\t{i[3]}\\n')\n",
    "        for i in val_df.itertuples():\n",
    "            if re.match('chr[0-9]', i[1]):\n",
    "                val_bed.write(f'{i[1]}\\t{i[2]}\\t{i[3]}\\n')\n",
    "        for i in test_df.itertuples():\n",
    "            if re.match('chr[0-9]', i[1]):\n",
    "                test_bed.write(f'{i[1]}\\t{i[2]}\\t{i[3]}\\n')\n",
    "        train_bed.close()\n",
    "        val_bed.close()\n",
    "        test_bed.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in negative regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 16421956 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:55<05:30, 55.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in negative regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 8190020 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [01:20<03:07, 37.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in negative regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 3251292 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [01:29<01:38, 24.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in negative regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 2154127 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [01:35<00:51, 17.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in negative regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 1605625 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [01:39<00:25, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in negative regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 783818 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [01:41<00:09,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in negative regions\n",
      "Deduplicating dataframe\n",
      "Generating index of 374548 examples\n",
      "\n",
      "Shuffling and splitting...\n",
      "Writing to files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:42<00:00, 14.71s/it]\n"
     ]
    }
   ],
   "source": [
    "### MOUSE ###\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "windows = [200, 400, 1000, 1500, 2000, 4000, 8000]\n",
    "# Read in bed file for all negative examples\n",
    "for w in tqdm(windows):\n",
    "    print(f'Reading in negative regions')\n",
    "    neg_df = pd.read_csv(f'../data/VISTA/mm9/neg_bed/mm9.VISTA'\n",
    "                         f'.non_enhancers.{w}bp.bed',\n",
    "                     header=None,\n",
    "                     index_col=None,\n",
    "                     sep='\\t')\n",
    "    print(\"Deduplicating dataframe\")\n",
    "    neg_dedup = neg_df.drop_duplicates()\n",
    "\n",
    "    print(f'Generating index of {neg_dedup.shape[0]} examples\\n')\n",
    "    neg_df_idx = np.arange(neg_dedup.shape[0])\n",
    "    print(f'Shuffling and splitting...')\n",
    "\n",
    "    shuf_idx = shuffle(neg_df_idx, random_state=12)\n",
    "\n",
    "    train_idx = shuf_idx[:int(len(shuf_idx)*0.7)]\n",
    "    val_idx = shuf_idx[int(len(shuf_idx)*0.7):int(len(shuf_idx)*0.9)]\n",
    "    test_idx = shuf_idx[int(len(shuf_idx)*0.9):]\n",
    "\n",
    "    train_df = neg_dedup.iloc[train_idx, :]\n",
    "    val_df = neg_dedup.iloc[val_idx, :]\n",
    "    test_df = neg_dedup.iloc[test_idx, :]\n",
    "\n",
    "    print('Writing to files')\n",
    "    train_bed = open(f'../data/VISTA/mm9/neg_bed/mm9.VISTA.non_enhancers'\n",
    "                     f'.{w}bp'\n",
    "                 f'.train.bed', 'w')\n",
    "    val_bed = open(f'../data/VISTA/mm9/neg_bed/mm9.VISTA.non_enhancers'\n",
    "                   f'.{w}bp'\n",
    "                 f'.val.bed', 'w')\n",
    "    test_bed = open(f'../data/VISTA/mm9/neg_bed/mm9.VISTA.non_enhancers'\n",
    "                    f'.{w}bp'\n",
    "                 f'.test.bed', 'w')\n",
    "    for i in train_df.itertuples():\n",
    "        if re.match('chr[0-9]', i[1]):\n",
    "            train_bed.write(f'{i[1]}\\t{i[2]}\\t{i[3]}\\n')\n",
    "    for i in val_df.itertuples():\n",
    "        if re.match('chr[0-9]', i[1]):\n",
    "            val_bed.write(f'{i[1]}\\t{i[2]}\\t{i[3]}\\n')\n",
    "    for i in test_df.itertuples():\n",
    "        if re.match('chr[0-9]', i[1]):\n",
    "            test_bed.write(f'{i[1]}\\t{i[2]}\\t{i[3]}\\n')\n",
    "    train_bed.close()\n",
    "    val_bed.close()\n",
    "    test_bed.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404101867\n",
      "2881033286\n",
      "48.73605153481035\n"
     ]
    }
   ],
   "source": [
    "chroms = pd.read_csv('../data/VISTA/hg19/originals/hg19.chrom.sizes',\n",
    "                     index_col=0,\n",
    "                     header=None,\n",
    "                     sep='\\t')\n",
    "non_genic = pd.read_csv('../data/VISTA/hg19/neg_bed/hg19.VISTA.non_genic'\n",
    "                        '.200bp.bed',\n",
    "                        header=None,\n",
    "                        index_col=None,\n",
    "                        sep='\\t')\n",
    "non_sum = 0\n",
    "ch = [f'chr{i}' for i in range(1,23)]\n",
    "for i in non_genic.itertuples():\n",
    "    non_sum += int(i[3]) - int(i[2])\n",
    "print(non_sum)\n",
    "geno = 0\n",
    "for i in chroms.itertuples():\n",
    "    if i[0] in ch:\n",
    "        geno += i[1]\n",
    "print(geno)\n",
    "print((non_sum/geno) * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove the sex chromosomes from the negative sets.\n",
    "\n",
    "\n",
    "Extract the fasta regions for each of the windows and dataset splits.\n",
    "```shell\n",
    "# Positive fastas\n",
    "for i in pos_bed/hg19.VISTA.enhancers.*.bed\n",
    "do\n",
    "  bedtools getfasta -fi ~/PhD/Reference_Genomes/hg19/hg19.fa -bed $i -fo ./pos_fa/$(basename -s .bed $i).fa\n",
    "done\n",
    "\n",
    "# Negative fastas\n",
    "for i in neg_bed/hg19.VISTA.non_enhancers.*.bed\n",
    "do\n",
    "  bedtools getfasta -fi ~/PhD/Reference_Genomes/hg19/hg19.fa -bed $i -fo ./neg_fa/$(basename -s .bed $i).fa\n",
    "done\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ensure no overlap between positive and negative bed files\n",
    "``` shell\n",
    "x=(200 400 1000 1500 2000 4000 8000)\n",
    "for i in ${x[@]}\n",
    " do\n",
    " bedtools intersect -a pos_bed/hg19.VISTA.enhancers.noXY.${i}bp.bed -b neg_bed/hg19.VISTA.non_enhancers.${i}bp.bed | wc -l\n",
    "done\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3361it [00:00, 33606.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on train at 1000bps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1921867it [00:32, 59406.43it/s]\n",
      "6313it [00:00, 63127.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on val at 1000bps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "548988it [00:09, 60024.21it/s]\n",
      "6097it [00:00, 60965.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test at 1000bps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "274557it [00:04, 59900.31it/s]\n",
      "4379it [00:00, 43781.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on train at 2000bps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "946258it [00:23, 40838.77it/s]\n",
      "4065it [00:00, 40644.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on val at 2000bps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "270352it [00:06, 39657.00it/s]\n",
      "3740it [00:00, 37395.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test at 2000bps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "135141it [00:03, 40894.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils import GC\n",
    "\n",
    "median = 41.290323\n",
    "std_dev = 7.487879\n",
    "count = 0\n",
    "split = ['train', 'val', 'test']\n",
    "bps = [1000, 2000] #[200, 400, 1000, 1500, 2000, 4000, 8000]\n",
    "for bp in bps:\n",
    "    for s in split:\n",
    "        print(f'Working on {s} at {bp}bps.')\n",
    "        fa = open(f'../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.noXY'\n",
    "             f'.GCbalanced.{bp}bp.{s}.fa', 'w')\n",
    "        for record in tqdm(SeqIO.parse(f'../data/VISTA/hg19/neg_fa/hg19.VISTA'\n",
    "                                   f'.non_enhancers'\n",
    "                          f'.{bp}bp.{s}.fa', 'fasta')):\n",
    "            if re.match('chr[A-Z|a-z]', record.name):\n",
    "                continue\n",
    "            if (median - std_dev) <= GC(record.seq) <= (median +\n",
    "                                                        std_dev):\n",
    "                fa.write(f'>{record.id}\\n{record.seq}\\n')\n",
    "        fa.close()\n",
    "        #print(record)\n",
    "        #print(GC(record.seq))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4781it [00:00, 47805.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on train at 1000bps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2004318it [00:36, 54527.25it/s]\n",
      "5800it [00:00, 57992.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on val at 1000bps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "572338it [00:10, 56785.24it/s]\n",
      "5849it [00:00, 58479.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test at 1000bps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "286200it [00:04, 58394.18it/s]\n",
      "4105it [00:00, 41040.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on train at 2000bps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "989093it [00:24, 40258.17it/s]\n",
      "4177it [00:00, 41767.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on val at 2000bps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "282632it [00:06, 41124.81it/s]\n",
      "3812it [00:00, 38115.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test at 2000bps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "141267it [00:03, 40265.90it/s]\n"
     ]
    }
   ],
   "source": [
    "### MOUSE ###\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils import GC\n",
    "\n",
    "median = 47.199045\n",
    "std_dev = 5.210994\n",
    "#count = 0\n",
    "split = ['train', 'val', 'test']\n",
    "bps = [1000, 2000] #[200, 400, 1000, 1500, 2000, 4000, 8000]\n",
    "for bp in bps:\n",
    "    for s in split:\n",
    "        print(f'Working on {s} at {bp}bps.')\n",
    "        fa = open(f'../data/VISTA/mm9/neg_fa/mm9.VISTA.non_enhancers.noXY'\n",
    "             f'.GCbalanced.{bp}bp.{s}.fa', 'w')\n",
    "        for record in tqdm(SeqIO.parse(f'../data/VISTA/mm9/neg_fa/mm9.VISTA'\n",
    "                                   f'.non_enhancers'\n",
    "                          f'.{bp}bp.{s}.fa', 'fasta')):\n",
    "            if re.match('chr[A-Z|a-z]', record.name):\n",
    "                continue\n",
    "            if (median - std_dev) <= GC(record.seq) <= (median +\n",
    "                                                        std_dev):\n",
    "                fa.write(f'>{record.id}\\n{record.seq}\\n')\n",
    "        fa.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we need to convert the fasta records into something that a ML or DL\n",
    "model can interpret.\n",
    "\n",
    "## 1. One-hot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.200bp.train.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250103/1250103 [01:18<00:00, 15854.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.200bp.train.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.200bp.val.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297305/297305 [00:19<00:00, 15521.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.200bp.val.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.200bp.test.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 302208/302208 [00:19<00:00, 15804.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.200bp.test.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.400bp.train.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1116303/1116303 [02:20<00:00, 7940.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.400bp.train.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.400bp.val.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267305/267305 [00:35<00:00, 7594.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.400bp.val.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.400bp.test.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 270008/270008 [00:33<00:00, 7947.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.400bp.test.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.1000bp.train.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 732339/732339 [03:44<00:00, 3260.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.1000bp.train.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.1000bp.val.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180157/180157 [00:54<00:00, 3330.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.1000bp.val.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.1000bp.test.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 170873/178395 [02:35<00:03, 2368.13it/s]"
     ]
    }
   ],
   "source": [
    "## Positive datasets ##\n",
    "from utils.utils import one_hot\n",
    "windows = [200, 400, 1000, 1500, 2000, 4000, 8000]\n",
    "split = ['train', 'val', 'test']\n",
    "for w in windows:\n",
    "    for s in split:\n",
    "        input_file = f'../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.{w}bp' \\\n",
    "                     f'.{s}.fa'\n",
    "        print(f'Converting {input_file} to one-hot encoded sequences.')\n",
    "        seq_dict = SeqIO.to_dict(SeqIO.parse(input_file, 'fasta'))\n",
    "        one_hot_seq = []\n",
    "        N_count = 0\n",
    "        for k, v in tqdm(seq_dict.items()):\n",
    "            if 'N' not in str(v.seq).upper():\n",
    "                one_hot_seq.append(one_hot(str(v.seq).upper()))\n",
    "            else:\n",
    "                N_count += 1\n",
    "        seq_array = np.array(one_hot_seq)\n",
    "        print(f'Saving converted {input_file} as npy array.')\n",
    "        np.save(f'../data/VISTA/hg19/pos_fa/hg19.VISTA.enhancers.{w}bp.{s}.npy',\n",
    "            seq_array)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.200bp.train.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9169276/9169276 [08:54<00:00, 17163.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.200bp.train.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.200bp.val.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2814335/2814335 [03:02<00:00, 15408.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.200bp.val.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.200bp.test.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1596908/1596908 [01:42<00:00, 15643.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.200bp.test.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.400bp.train.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4568394/4568394 [08:48<00:00, 8642.22it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.400bp.train.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.400bp.val.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1403636/1403636 [02:48<00:00, 8351.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.400bp.val.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.400bp.test.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 795704/795704 [01:40<00:00, 7878.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.400bp.test.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.1000bp.train.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1808407/1808407 [07:51<00:00, 3836.34it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.1000bp.train.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.1000bp.val.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557289/557289 [02:52<00:00, 3235.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.1000bp.val.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.1000bp.test.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315038/315038 [01:38<00:00, 3208.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.1000bp.test.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.1500bp.train.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1195377/1195377 [08:29<00:00, 2348.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.1500bp.train.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.1500bp.val.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 369240/369240 [02:41<00:00, 2284.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.1500bp.val.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.1500bp.test.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208295/208295 [01:34<00:00, 2206.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.1500bp.test.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.2000bp.train.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 889023/889023 [08:02<00:00, 1842.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.2000bp.train.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.2000bp.val.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275245/275245 [02:52<00:00, 1597.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.2000bp.val.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.2000bp.test.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154904/154904 [01:30<00:00, 1703.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.2000bp.test.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.4000bp.train.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 430306/430306 [07:41<00:00, 931.92it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.4000bp.train.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.4000bp.val.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134400/134400 [02:39<00:00, 841.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.4000bp.val.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.4000bp.test.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74983/74983 [01:33<00:00, 802.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.4000bp.test.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.8000bp.train.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 202497/202497 [07:12<00:00, 468.23it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.8000bp.train.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.8000bp.val.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64197/64197 [02:27<00:00, 434.27it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.8000bp.val.fa as npy array.\n",
      "Converting ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.8000bp.test.fa to one-hot encoded sequences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35243/35243 [01:23<00:00, 422.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted ../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers.8000bp.test.fa as npy array.\n"
     ]
    }
   ],
   "source": [
    "## Negative Datasets ##\n",
    "\n",
    "from utils.utils import one_hot\n",
    "windows = [200, 400, 1000, 1500, 2000, 4000, 8000]\n",
    "split = ['train', 'val', 'test']\n",
    "for w in windows:\n",
    "    for s in split:\n",
    "\n",
    "        input_file = f'../data/VISTA/hg19/neg_fa/hg19.VISTA.non_enhancers' \\\n",
    "                     f'.{w}bp.{s}.fa'\n",
    "        print(f'Converting {input_file} to one-hot encoded sequences.')\n",
    "        seq_dict = SeqIO.to_dict(SeqIO.parse(input_file, 'fasta'))\n",
    "        one_hot_seq = []\n",
    "        N_count = 0\n",
    "        for k, v in tqdm(seq_dict.items()):\n",
    "            if 'N' not in str(v.seq).upper():\n",
    "                one_hot_seq.append(one_hot(str(v.seq).upper()))\n",
    "            else:\n",
    "                N_count += 1\n",
    "        seq_array = np.array(one_hot_seq)\n",
    "        print(f'Saving converted {input_file} as npy array.')\n",
    "        np.save(f'../data/VISTA/hg19/neg_npy/hg19.VISTA.non_enhancers.{w}bp'\n",
    "            f'.{s}'\n",
    "            f'.npy',\n",
    "            seq_array)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "for s in split:\n",
    "    pos_arr = np.load(f'../data/VISTA/hg19/pos_npy/hg19.VISTA.enhancers.200bp'\n",
    "                      f'.{s}.npy', mmap_mode='r')\n",
    "    neg_arr = np.load(f'../data/VISTA/hg19/neg_npy/hg19.VISTA.non_enhancers'\n",
    "                      f'.200bp.{s}.npy', mmap_mode='r')\n",
    "\n",
    "    pos_lab = np.ones(pos_arr.shape[0])\n",
    "    neg_lab = np.zeros(neg_arr.shape[0])\n",
    "\n",
    "    dat_arr = np.vstack((pos_arr, neg_arr))\n",
    "    lab_arr = np.hstack((pos_lab, neg_lab))\n",
    "\n",
    "    np.save(f'../data/VISTA/hg19/datasets/hg19.VISTA.unbalanced.200bp.{s}_X'\n",
    "            f'.npy', dat_arr)\n",
    "    np.save(f'../data/VISTA/hg19/datasets/hg19.VISTA.unbalanced.200bp.{s}_y'\n",
    "            f'.npy', lab_arr)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:18<00:00, 46.12s/it]\n"
     ]
    }
   ],
   "source": [
    "for s in tqdm(split):\n",
    "    pos_arr = np.load(f'../data/VISTA/hg19/pos_npy/hg19.VISTA.enhancers.200bp'\n",
    "                      f'.{s}.npy', mmap_mode='r')\n",
    "    neg_arr = np.load(f'../data/VISTA/hg19/neg_npy/hg19.VISTA.non_enhancers'\n",
    "                      f'.200bp.balanced.{s}.npy', mmap_mode='r')\n",
    "\n",
    "    pos_lab = np.ones(pos_arr.shape[0])\n",
    "    neg_lab = np.zeros(neg_arr.shape[0])\n",
    "\n",
    "    dat_arr = np.vstack((pos_arr, neg_arr))\n",
    "    lab_arr = np.hstack((pos_lab, neg_lab))\n",
    "\n",
    "    np.save(f'../data/VISTA/hg19/datasets/hg19.VISTA.balanced.200bp.{s}_X'\n",
    "            f'.npy', dat_arr)\n",
    "    np.save(f'../data/VISTA/hg19/datasets/hg19.VISTA.balanced.200bp.{s}_y'\n",
    "            f'.npy', lab_arr)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Word Vectors with FastText\n",
    "- This section assumes you already have the `.vec` and `.bin` files\n",
    "after\n",
    "`fasttext` has finished representing words as vectors."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_vec = pd.read_csv('/Users/callummacphillamy/PhD/Reference_Genomes/hg19'\n",
    "                       '/hg19.skipgram.vec',\n",
    "                       header=None,\n",
    "                       index_col=0,\n",
    "                       sep=' ',\n",
    "                       skiprows=1)\n",
    "word_vec = word_vec.iloc[:, :100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. DNA as an Image\n",
    "A somewhat unexplored area of research in terms of enhancer prediction, but\n",
    "converting DNA to an image would likely improve a CNN's ability to extract\n",
    "features from it. This also has the potential to be applied to predicting the\n",
    " targets of enhancers.\n",
    "DNA as an image is based on this [paper](https://arxiv.org/pdf/1806.04931.pdf)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "nuc = ['A', 'C', 'G', 'T']\n",
    "itertools.product(nuc, repeat=len(nuc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}