{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils.utils import seq2img2D\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "import time\n",
    "import random\n",
    "from hilbertcurve.hilbertcurve import HilbertCurve\n",
    "import itertools\n",
    "\n",
    "def seq2img2D(in_fa, hc_p=1 , hc_n=2,\n",
    "            random_choice=False,\n",
    "            rand_n=None):\n",
    "    \"\"\"\n",
    "    Function to convert dna sequence to an n x n image where each pixel value is\n",
    "    determined by what 4mer is in that position.\n",
    "\n",
    "    :param in_fa: Multifasta file to be converted\n",
    "    :param hc_p: Order for the hilbert curve. Default = 1\n",
    "    :param hc_n: Number of dimensions for hilbert curve. Default=2\n",
    "    :param random_choice: Bool. If true, will take a random selection of\n",
    "    records from the dictionary equal to size of rand_n.\n",
    "    :param rand_n: Number of records to use if random_choice is True.\n",
    "    :return: ndarray of shape N, H, W. Where N is the\n",
    "    number of records in the multifasta file, H height 2**hc_p. W width 2**hc_p.\n",
    "    \"\"\"\n",
    "    # Generate the Hilbert Curve\n",
    "    print(f'Generating hilbert curve of order {hc_p} with {hc_n} dimensions.\\n')\n",
    "    HC = HilbertCurve(n=hc_n, p=hc_p)\n",
    "    points = HC.points_from_distances(distances=list(range(int(2**hc_p)**2)))\n",
    "\n",
    "    # Generate the mapping dictionary for values. Here, we are using 4mers so\n",
    "    # all possible 4mers we can have is 256. 4 nucleotides to the power of\n",
    "    # 4mer = 256 possible kmers.\n",
    "    print(f'Generating mapping dictionary for all possible 4mers\\n')\n",
    "    def mapping_dict():\n",
    "        nuc = [''.join(n) for n in\n",
    "               itertools.product(['A', 'C', 'G', 'T'], repeat=4)]\n",
    "        nuc_dict = {}\n",
    "        for k, i in enumerate(nuc):\n",
    "            # print(k, i)\n",
    "            nuc_dict[f'{i}'] = k + 1.\n",
    "        return nuc_dict\n",
    "\n",
    "\n",
    "    print(f'Reading in {in_fa} to a dictionary\\nRemoving records with N\\'s\\n')\n",
    "    multi_fa = SeqIO.to_dict(SeqIO.parse(in_fa, 'fasta'))\n",
    "    clean_multi_fa = {}\n",
    "    for k, v in tqdm(multi_fa.items()):\n",
    "        if 'N' not in str(v.seq).upper() and k not in clean_multi_fa:\n",
    "            clean_multi_fa[f'{k}'] = v\n",
    "        elif f'{k}' in clean_multi_fa:\n",
    "            print(f'Key: {k} already in dictionary, adding \".2\" to the key.')\n",
    "            clean_multi_fa[f'{k}.2'] = v\n",
    "        elif f'{k}.2' in clean_multi_fa:\n",
    "            print(f'Key: {k} already in dictionary, adding \".3\" to the key.')\n",
    "            clean_multi_fa[f'{k}.3'] = v\n",
    "    if random_choice is True:\n",
    "        random.seed(12)\n",
    "        rand_clean_idx = random.sample(list(clean_multi_fa), k=rand_n)\n",
    "        clean_fa = {key: clean_multi_fa[key] for key in rand_clean_idx}\n",
    "        print(f'Number of clean records taken randomly: {rand_n}')\n",
    "    else:\n",
    "        clean_fa = clean_multi_fa\n",
    "        print(f'Number of records before N removal: {len(multi_fa)}\\nNumber of '\n",
    "          f'records after N removal: {len(clean_fa)}\\n')\n",
    "    start_time = time.time()\n",
    "    nuc_dict = mapping_dict()\n",
    "    print(f'Generating array dataset of shape '\n",
    "          f'{len(clean_fa)}, {2**hc_p}, {2**hc_p}\\n')\n",
    "    img_mat = np.zeros((len(clean_fa), 2**hc_p, 2**hc_p))\n",
    "    nuc_channel = list(nuc_dict.keys())\n",
    "    print(f'Beginning sequencing to image conversion for {in_fa}.')\n",
    "    for k, record in enumerate(tqdm(clean_fa.items())):\n",
    "        for i in range(int(len(str(record[1].seq).upper())-4 + 1)):\n",
    "            nc = nuc_channel.index(f'{str(record[1].seq).upper()[i:i+4]}')\n",
    "            img_mat[k][points[i][1]][points[i][0]] = nc\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f'Time taken to create image array: {total_time/60} mins')\n",
    "    return img_mat / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For seq length = 2000, I'm using a Hilbert Curve at order: 6.\n",
      "Generating hilbert curve of order 6 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Fantom5/enhancer/hg19/pos_fa/hg19.Fantom5.enhancers.noXY.2000bp.train.fa to a dictionary\n",
      "Removing records with N's\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47421/47421 [00:00<00:00, 438831.29it/s]\n",
      "  0%|                                                                                                                                                                                                                                                        | 12/47401 [00:00<06:56, 113.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records before N removal: 47421\n",
      "Number of records after N removal: 47401\n",
      "\n",
      "Generating array dataset of shape 47401, 64, 64\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Fantom5/enhancer/hg19/pos_fa/hg19.Fantom5.enhancers.noXY.2000bp.train.fa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47401/47401 [06:54<00:00, 114.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 6.903181167443593 mins\n",
      "Saving train at 2000bps as seq2img numpy array.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13549/13549 [00:00<00:00, 574061.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For seq length = 2000, I'm using a Hilbert Curve at order: 6.\n",
      "Generating hilbert curve of order 6 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Fantom5/enhancer/hg19/pos_fa/hg19.Fantom5.enhancers.noXY.2000bp.val.fa to a dictionary\n",
      "Removing records with N's\n",
      "\n",
      "Number of records before N removal: 13549\n",
      "Number of records after N removal: 13548\n",
      "\n",
      "Generating array dataset of shape 13548, 64, 64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|▎                                                                                                                                                                                                                                                       | 14/13548 [00:00<01:43, 130.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning sequencing to image conversion for ../data/Fantom5/enhancer/hg19/pos_fa/hg19.Fantom5.enhancers.noXY.2000bp.val.fa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13548/13548 [01:54<00:00, 118.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 1.910838536421458 mins\n",
      "Saving val at 2000bps as seq2img numpy array.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6775/6775 [00:00<00:00, 501994.62it/s]\n",
      "  0%|                                                                                                                                                                                                                                                                   | 0/6775 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For seq length = 2000, I'm using a Hilbert Curve at order: 6.\n",
      "Generating hilbert curve of order 6 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Fantom5/enhancer/hg19/pos_fa/hg19.Fantom5.enhancers.noXY.2000bp.test.fa to a dictionary\n",
      "Removing records with N's\n",
      "\n",
      "Number of records before N removal: 6775\n",
      "Number of records after N removal: 6775\n",
      "\n",
      "Generating array dataset of shape 6775, 64, 64\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Fantom5/enhancer/hg19/pos_fa/hg19.Fantom5.enhancers.noXY.2000bp.test.fa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6775/6775 [00:53<00:00, 125.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 0.900128964583079 mins\n",
      "Saving test at 2000bps as seq2img numpy array.\n",
      "\n",
      "For seq length = 2000, I'm using a Hilbert Curve at order: 6.\n",
      "Generating hilbert curve of order 6 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Fantom5/enhancer/mm9/pos_fa/mm9.Fantom5.enhancers.noXY.2000bp.train.fa to a dictionary\n",
      "Removing records with N's\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30614/30614 [00:00<00:00, 510930.20it/s]\n",
      "  0%|                                                                                                                                                                                                                                                        | 13/30596 [00:00<04:04, 125.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records before N removal: 30614\n",
      "Number of records after N removal: 30596\n",
      "\n",
      "Generating array dataset of shape 30596, 64, 64\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Fantom5/enhancer/mm9/pos_fa/mm9.Fantom5.enhancers.noXY.2000bp.train.fa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30596/30596 [04:06<00:00, 124.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 4.1079403003056845 mins\n",
      "Saving train at 2000bps as seq2img numpy array.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8747/8747 [00:00<00:00, 548878.34it/s]\n",
      "  0%|                                                                                                                                                                                                                                                                   | 0/8739 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For seq length = 2000, I'm using a Hilbert Curve at order: 6.\n",
      "Generating hilbert curve of order 6 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Fantom5/enhancer/mm9/pos_fa/mm9.Fantom5.enhancers.noXY.2000bp.val.fa to a dictionary\n",
      "Removing records with N's\n",
      "\n",
      "Number of records before N removal: 8747\n",
      "Number of records after N removal: 8739\n",
      "\n",
      "Generating array dataset of shape 8739, 64, 64\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Fantom5/enhancer/mm9/pos_fa/mm9.Fantom5.enhancers.noXY.2000bp.val.fa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8739/8739 [01:04<00:00, 135.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 1.0736771861712138 mins\n",
      "Saving val at 2000bps as seq2img numpy array.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4374/4374 [00:00<00:00, 640881.91it/s]\n",
      "  0%|                                                                                                                                                                                                                                                                   | 0/4369 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For seq length = 2000, I'm using a Hilbert Curve at order: 6.\n",
      "Generating hilbert curve of order 6 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Fantom5/enhancer/mm9/pos_fa/mm9.Fantom5.enhancers.noXY.2000bp.test.fa to a dictionary\n",
      "Removing records with N's\n",
      "\n",
      "Number of records before N removal: 4374\n",
      "Number of records after N removal: 4369\n",
      "\n",
      "Generating array dataset of shape 4369, 64, 64\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Fantom5/enhancer/mm9/pos_fa/mm9.Fantom5.enhancers.noXY.2000bp.test.fa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4369/4369 [00:31<00:00, 136.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 0.532866366704305 mins\n",
      "Saving test at 2000bps as seq2img numpy array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## POSITIVE EXAMPLES ##\n",
    "split = ['train', 'val', 'test']\n",
    "bps = [2000] #,1000]\n",
    "species = ['hg19', 'mm9']\n",
    "for sp in species:\n",
    "    for s in split:\n",
    "        for bp in bps:\n",
    "            #if exists(f'../data/Fantom5/enhancer/{sp}/pos_npy/{sp}.Fantom5.enhancers.noXY'\n",
    "            #          f'.seq2img.{bp}bp.{s}.npy'):\n",
    "            #    continue\n",
    "            #print(f'Converting seq2img for {sp} {s} at {bp}bps.')\n",
    "            if bp <= (2**4)**2:\n",
    "                p = 4\n",
    "            elif (2**4)**2 < bp <= (2**5)**2:\n",
    "                p = 5\n",
    "            elif (2**5)**2 < bp <= (2**6)**2:\n",
    "                p = 6\n",
    "            print(f'For seq length = {bp}, I\\'m using a Hilbert Curve at order: '\n",
    "                  f'{p}.')\n",
    "            mat = seq2img2D(f'../data/Fantom5/enhancer/{sp}/pos_fa/{sp}.Fantom5.enhancers.noXY'\n",
    "                         f'.{bp}bp.{s}.fa',\n",
    "                          hc_p=p,\n",
    "                          hc_n=2)\n",
    "            print(f'Saving {s} at {bp}bps as seq2img numpy array.\\n')\n",
    "            np.save(f'../data/Fantom5/enhancer/{sp}/pos_npy/{sp}.Fantom5.enhancers.noXY'\n",
    "                    f'.seq2img'\n",
    "                    f'.{bp}bp'\n",
    "                    f'.{s}.npy', mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting hg19 train at 2000bps into an image.\n",
      "Number of positive samples:\t47401\n",
      "Generating hilbert curve of order 6 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Fantom5/enhancer/hg19/neg_fa/hg19.Fantom5.non_enhancers.noXY.GCbalanced.2000bp.train.fa to a dictionary\n",
      "Removing records with N's\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 619671/619671 [00:01<00:00, 505102.26it/s]\n",
      "  0%|                                                                                                                                                                                                                                                        | 12/47401 [00:00<06:57, 113.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clean records taken randomly: 47401\n",
      "Generating array dataset of shape 47401, 64, 64\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Fantom5/enhancer/hg19/neg_fa/hg19.Fantom5.non_enhancers.noXY.GCbalanced.2000bp.train.fa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47401/47401 [05:48<00:00, 135.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 5.813872329394022 mins\n",
      "Saving train at 2000 as seq2img numpy array.\n",
      "\n",
      "Converting hg19 val at 2000bps into an image.\n",
      "Number of positive samples:\t13548\n",
      "Generating hilbert curve of order 6 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Fantom5/enhancer/hg19/neg_fa/hg19.Fantom5.non_enhancers.noXY.GCbalanced.2000bp.val.fa to a dictionary\n",
      "Removing records with N's\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 177420/177420 [00:00<00:00, 521691.60it/s]\n",
      "  0%|▏                                                                                                                                                                                                                                                       | 13/13548 [00:00<01:47, 125.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clean records taken randomly: 13548\n",
      "Generating array dataset of shape 13548, 64, 64\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Fantom5/enhancer/hg19/neg_fa/hg19.Fantom5.non_enhancers.noXY.GCbalanced.2000bp.val.fa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13548/13548 [01:39<00:00, 135.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 1.661734700202942 mins\n",
      "Saving val at 2000 as seq2img numpy array.\n",
      "\n",
      "Converting hg19 test at 2000bps into an image.\n",
      "Number of positive samples:\t6775\n",
      "Generating hilbert curve of order 6 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Fantom5/enhancer/hg19/neg_fa/hg19.Fantom5.non_enhancers.noXY.GCbalanced.2000bp.test.fa to a dictionary\n",
      "Removing records with N's\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 88558/88558 [00:00<00:00, 516361.79it/s]\n",
      "  0%|▌                                                                                                                                                                                                                                                        | 15/6775 [00:00<00:47, 142.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clean records taken randomly: 6775\n",
      "Generating array dataset of shape 6775, 64, 64\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Fantom5/enhancer/hg19/neg_fa/hg19.Fantom5.non_enhancers.noXY.GCbalanced.2000bp.test.fa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6775/6775 [00:49<00:00, 136.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 0.8271453301111857 mins\n",
      "Saving test at 2000 as seq2img numpy array.\n",
      "\n",
      "Converting mm9 train at 2000bps into an image.\n",
      "Number of positive samples:\t30596\n",
      "Generating hilbert curve of order 6 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Fantom5/enhancer/mm9/neg_fa/mm9.Fantom5.non_enhancers.noXY.GCbalanced.2000bp.train.fa to a dictionary\n",
      "Removing records with N's\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 655792/655792 [00:01<00:00, 506193.09it/s]\n",
      "  0%|                                                                                                                                                                                                                                                        | 12/30596 [00:00<04:31, 112.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clean records taken randomly: 30596\n",
      "Generating array dataset of shape 30596, 64, 64\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Fantom5/enhancer/mm9/neg_fa/mm9.Fantom5.non_enhancers.noXY.GCbalanced.2000bp.train.fa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30596/30596 [04:06<00:00, 124.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 4.104665950934092 mins\n",
      "Saving train at 2000 as seq2img numpy array.\n",
      "\n",
      "Converting mm9 val at 2000bps into an image.\n",
      "Number of positive samples:\t8739\n",
      "Generating hilbert curve of order 6 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Fantom5/enhancer/mm9/neg_fa/mm9.Fantom5.non_enhancers.noXY.GCbalanced.2000bp.val.fa to a dictionary\n",
      "Removing records with N's\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 187392/187392 [00:00<00:00, 385870.01it/s]\n",
      "  0%|▎                                                                                                                                                                                                                                                          | 9/8739 [00:00<01:45, 82.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clean records taken randomly: 8739\n",
      "Generating array dataset of shape 8739, 64, 64\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Fantom5/enhancer/mm9/neg_fa/mm9.Fantom5.non_enhancers.noXY.GCbalanced.2000bp.val.fa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8739/8739 [01:20<00:00, 108.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 1.343127969900767 mins\n",
      "Saving val at 2000 as seq2img numpy array.\n",
      "\n",
      "Converting mm9 test at 2000bps into an image.\n",
      "Number of positive samples:\t4369\n",
      "Generating hilbert curve of order 6 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Fantom5/enhancer/mm9/neg_fa/mm9.Fantom5.non_enhancers.noXY.GCbalanced.2000bp.test.fa to a dictionary\n",
      "Removing records with N's\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93295/93295 [00:00<00:00, 495806.18it/s]\n",
      "  0%|▋                                                                                                                                                                                                                                                        | 13/4369 [00:00<00:34, 124.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clean records taken randomly: 4369\n",
      "Generating array dataset of shape 4369, 64, 64\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Fantom5/enhancer/mm9/neg_fa/mm9.Fantom5.non_enhancers.noXY.GCbalanced.2000bp.test.fa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4369/4369 [00:34<00:00, 126.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 0.5746066451072693 mins\n",
      "Saving test at 2000 as seq2img numpy array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    " ## NEGATIVE EXAMPLES ##\n",
    "split = ['train', 'val', 'test']\n",
    "species = ['hg19','mm9']#, 'mm9']\n",
    "bps = [2000] #, 1000]\n",
    "for sp in species:\n",
    "    for s in split:\n",
    "        for bp in bps:\n",
    "            print(f'Converting {sp} {s} at {bp}bps into an image.')\n",
    "            pos_X = np.load(f'../data/Fantom5/enhancer/{sp}/pos_npy/{sp}.Fantom5.enhancers.noXY'\n",
    "                    f'.seq2img'\n",
    "                    f'.{bp}bp'\n",
    "                    f'.{s}.npy', mmap_mode='r')\n",
    "            print(f'Number of positive samples:\\t{pos_X.shape[0]}')\n",
    "            if bp <= (2**4)**2:\n",
    "                p = 4\n",
    "            elif (2**4)**2 < bp <= (2**5)**2:\n",
    "                p = 5\n",
    "            elif (2**5)**2 < bp <= (2**6)**2:\n",
    "                p = 6\n",
    "            elif (2**6)**2 < bp <= (2**7)**2:\n",
    "                p = 7\n",
    "            mat = seq2img2D(f'../data/Fantom5/enhancer/{sp}/neg_fa/{sp}.Fantom5.non_enhancers'\n",
    "                          f'.noXY.GCbalanced.{bp}bp.{s}.fa',\n",
    "                          hc_p=p,\n",
    "                          hc_n=2,\n",
    "                          random_choice=True,\n",
    "                          rand_n = pos_X.shape[0])\n",
    "            print(f'Saving {s} at {bp} as seq2img numpy array.\\n')\n",
    "            np.save(f'../data/Fantom5/enhancer/{sp}/neg_npy/{sp}.Fantom5.non_enhancers.noXY'\n",
    "                    f'.GCbalanced'\n",
    "                    f'.seq2img'\n",
    "                    f'.{bp}bp'\n",
    "                    f'.{s}.npy', mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging pos and neg sets\n",
      "Saving train at 2000bp\n",
      "Merging pos and neg sets\n",
      "Saving val at 2000bp\n",
      "Merging pos and neg sets\n",
      "Saving test at 2000bp\n",
      "Merging pos and neg sets\n",
      "Saving train at 2000bp\n",
      "Merging pos and neg sets\n",
      "Saving val at 2000bp\n",
      "Merging pos and neg sets\n",
      "Saving test at 2000bp\n"
     ]
    }
   ],
   "source": [
    "split = ['train', 'val', 'test']\n",
    "bps = [2000] #, 1000]\n",
    "species = ['hg19','mm9']\n",
    "for sp in species:\n",
    "    for s in split:\n",
    "        for bp in bps:\n",
    "\n",
    "            pos_X = np.load(f'../data/Fantom5/enhancer/{sp}/pos_npy/{sp}.Fantom5.enhancers'\n",
    "                        f'.noXY.seq2img.{bp}bp.{s}.npy', mmap_mode='r')\n",
    "            neg_X = np.load(f'../data/Fantom5/enhancer/{sp}/neg_npy/{sp}.Fantom5.non_enhancers'\n",
    "                        f'.noXY.GCbalanced.seq2img.{bp}bp.{s}.npy')\n",
    "            if bp <= 2000 and s == 'train':\n",
    "                assert pos_X.shape[0] == neg_X.shape[0], 'pos and neg not equal'\n",
    "            if bp <= 2000 and s == 'val':\n",
    "                assert pos_X.shape[0] == neg_X.shape[0], 'pos and neg not equal'\n",
    "                #assert neg_X.shape[0] == 25000, 'neg shape not equal to 25,000'\n",
    "            if bp <= 2000 and s == 'test':\n",
    "                assert pos_X.shape[0] == neg_X.shape[0], 'pos and neg not equal'\n",
    "                #assert neg_X.shape[0] == 10000, 'neg shape not equal to 10,000'\n",
    "\n",
    "            pos_y = np.ones(pos_X.shape[0])\n",
    "            neg_y = np.zeros(neg_X.shape[0])\n",
    "\n",
    "            print(f'Merging pos and neg sets')\n",
    "            dat = np.vstack((pos_X, neg_X))\n",
    "            lab = np.hstack((pos_y, neg_y))\n",
    "\n",
    "            print(f'Saving {s} at {bp}bp')\n",
    "            np.save(f'../data/Fantom5/enhancer/{sp}/datasets/{sp}.balanced.Fantom5.seq2img'\n",
    "                    f'.{bp}bp'\n",
    "                    f'.{s}_X.npy', dat)\n",
    "            np.save(f'../data/Fantom5/enhancer/{sp}/datasets/{sp}.balanced.Fantom5.seq2img'\n",
    "                    f'.{bp}bp'\n",
    "                    f'.{s}_y.npy', lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 742/742 [00:00<00:00, 355514.46it/s]\n",
      " 11%|█         | 83/742 [00:00<00:00, 824.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting strong enhancers from train to an image.\n",
      "Generating hilbert curve of order 4 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Enhancer_strength/train/originals/data_strong_enhancers.txt to a dictionary\n",
      "Removing records with N's\n",
      "\n",
      "Number of records before N removal: 742\n",
      "Number of records after N removal: 742\n",
      "\n",
      "Generating array dataset of shape 742, 16, 16\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Enhancer_strength/train/originals/data_strong_enhancers.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 742/742 [00:00<00:00, 988.03it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 116153.53it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 811.95it/s]\n",
      "100%|██████████| 742/742 [00:00<00:00, 349643.14it/s]\n",
      "  0%|          | 0/742 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 0.012561949094136556 mins\n",
      "Saving strong enhancers from train as seq2img numpy array.\n",
      "\n",
      "Converting strong enhancers from test to an image.\n",
      "Generating hilbert curve of order 4 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Enhancer_strength/test/originals/test_strong_enhancers.txt to a dictionary\n",
      "Removing records with N's\n",
      "\n",
      "Number of records before N removal: 100\n",
      "Number of records after N removal: 100\n",
      "\n",
      "Generating array dataset of shape 100, 16, 16\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Enhancer_strength/test/originals/test_strong_enhancers.txt.\n",
      "Time taken to create image array: 0.0021361311276753745 mins\n",
      "Saving strong enhancers from test as seq2img numpy array.\n",
      "\n",
      "Converting weak enhancers from train to an image.\n",
      "Generating hilbert curve of order 4 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Enhancer_strength/train/originals/data_weak_enhancers.txt to a dictionary\n",
      "Removing records with N's\n",
      "\n",
      "Number of records before N removal: 742\n",
      "Number of records after N removal: 742\n",
      "\n",
      "Generating array dataset of shape 742, 16, 16\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Enhancer_strength/train/originals/data_weak_enhancers.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 742/742 [00:00<00:00, 1144.48it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 861253.39it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 928.83it/s]\n",
      "100%|██████████| 1484/1484 [00:00<00:00, 503262.22it/s]\n",
      "  0%|          | 0/1484 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 0.010837348302205403 mins\n",
      "Saving weak enhancers from train as seq2img numpy array.\n",
      "\n",
      "Converting weak enhancers from test to an image.\n",
      "Generating hilbert curve of order 4 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Enhancer_strength/test/originals/test_weak_enhancers.txt to a dictionary\n",
      "Removing records with N's\n",
      "\n",
      "Number of records before N removal: 100\n",
      "Number of records after N removal: 100\n",
      "\n",
      "Generating array dataset of shape 100, 16, 16\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Enhancer_strength/test/originals/test_weak_enhancers.txt.\n",
      "Time taken to create image array: 0.0018214702606201172 mins\n",
      "Saving weak enhancers from test as seq2img numpy array.\n",
      "\n",
      "Converting non enhancers from train to an image.\n",
      "Generating hilbert curve of order 4 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Enhancer_strength/train/originals/data_non_enhancers.txt to a dictionary\n",
      "Removing records with N's\n",
      "\n",
      "Number of records before N removal: 1484\n",
      "Number of records after N removal: 1484\n",
      "\n",
      "Generating array dataset of shape 1484, 16, 16\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Enhancer_strength/train/originals/data_non_enhancers.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1484/1484 [00:01<00:00, 1147.32it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 1030541.52it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 1353.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create image array: 0.02159657080968221 mins\n",
      "Saving non enhancers from train as seq2img numpy array.\n",
      "\n",
      "Converting non enhancers from test to an image.\n",
      "Generating hilbert curve of order 4 with 2 dimensions.\n",
      "\n",
      "Generating mapping dictionary for all possible 4mers\n",
      "\n",
      "Reading in ../data/Enhancer_strength/test/originals/test_non_enhancers.txt to a dictionary\n",
      "Removing records with N's\n",
      "\n",
      "Number of records before N removal: 200\n",
      "Number of records after N removal: 200\n",
      "\n",
      "Generating array dataset of shape 200, 16, 16\n",
      "\n",
      "Beginning sequencing to image conversion for ../data/Enhancer_strength/test/originals/test_non_enhancers.txt.\n",
      "Time taken to create image array: 0.0024828314781188965 mins\n",
      "Saving non enhancers from test as seq2img numpy array.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "strength = ['strong', 'weak', 'non']\n",
    "split = ['train', 'test']\n",
    "for st in strength:\n",
    "    for sp in split:\n",
    "        print(f'Converting {st} enhancers from {sp} to an image.')\n",
    "        if sp == 'test':\n",
    "            mat = seq2img2D(f'.'\n",
    "                        f'./data/Enhancer_strength/{sp}/originals'\n",
    "                        f'/test_{st}_enhancers.txt',\n",
    "                      hc_p=4,\n",
    "                      hc_n=2)\n",
    "        else:\n",
    "            mat = seq2img2D(f'.'\n",
    "                        f'./data/Enhancer_strength/{sp}/originals'\n",
    "                        f'/data_{st}_enhancers.txt',\n",
    "                      hc_p=4,\n",
    "                      hc_n=2)\n",
    "        print(f'Saving {st} enhancers from {sp} as seq2img numpy array.\\n')\n",
    "        np.save(f'../data/Enhancer_strength/{sp}/seq2img/data.{st}.enhancers'\n",
    "                f'.seq2img.npy',\n",
    "                mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fa = open('../data/Enhancer_strength/test/originals/test_non_enhancers'\n",
    "     '.txt', 'w')\n",
    "names = []\n",
    "for record in SeqIO.parse('../data/Enhancer_strength/test/originals'\n",
    "                    '/original_test_non_enhancers.txt', 'fasta'):\n",
    "    if record.name not in names:\n",
    "        names.append(record.name)\n",
    "        fa.write(f'>{record.name}\\n{record.seq}\\n')\n",
    "    elif record.name in names:\n",
    "        fa.write(f'>{record.name}.{names.count(record.name) + 1}\\n{record.seq}\\n')\n",
    "fa.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining human and mouse train datasets at 200bp.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:54<00:00, 54.37s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining human and mouse val datasets at 200bp.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:22<00:00, 22.94s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining human and mouse test datasets at 200bp.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.00s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "split = ['train', 'val', 'test']\n",
    "window = [200]#, 1000]\n",
    "for s in split:\n",
    "    for w in tqdm(window):\n",
    "        print(f'Combining human and mouse {s} datasets at {w}bp.')\n",
    "        human_X = np.load(f'../data/VISTA/hg19/datasets/hg19.balanced.VISTA'\n",
    "                          f'.seq2img.{w}bp.{s}_X.npy', mmap_mode='r')\n",
    "        mouse_X = np.load(f'../data/VISTA/mm9/datasets/mm9.balanced.VISTA'\n",
    "                          f'.seq2img.{w}bp.{s}_X.npy', mmap_mode='r')\n",
    "        human_y = np.load(f'../data/VISTA/hg19/datasets/hg19.balanced.VISTA'\n",
    "                          f'.seq2img.{w}bp.{s}_y.npy', mmap_mode='r')\n",
    "        mouse_y = np.load(f'../data/VISTA/mm9/datasets/mm9.balanced.VISTA'\n",
    "                          f'.seq2img.{w}bp.{s}_y.npy', mmap_mode='r')\n",
    "\n",
    "        comb_X = np.vstack((human_X, mouse_X))\n",
    "        comb_y = np.hstack((human_y, mouse_y))\n",
    "\n",
    "        np.save(f'../data/VISTA/hg19.mm9.balanced.VISTA.seq2img.{w}bp.{s}_X'\n",
    "                f'.npy', comb_X)\n",
    "        np.save(f'../data/VISTA/hg19.mm9.balanced.VISTA.seq2img.{w}bp.{s}_y'\n",
    "                f'.npy', comb_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [16:34<00:00, 331.59s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "split = ['train', 'val', 'test']\n",
    "\n",
    "for s in tqdm(split):\n",
    "    hg19_dat = np.load(f'../data/VISTA/hg19/datasets/hg19.balanced.VISTA'\n",
    "                       f'.onehot.1000bp.{s}_X.npy', mmap_mode='r')\n",
    "    hg19_lab = np.load(f'../data/VISTA/hg19/datasets/hg19.balanced.VISTA'\n",
    "                       f'.onehot.1000bp.{s}_y.npy', mmap_mode='r')\n",
    "\n",
    "    mm9_dat = np.load(f'../data/VISTA/mm9/datasets/mm9.balanced.VISTA'\n",
    "                       f'.onehot.1000bp.{s}_X.npy', mmap_mode='r')\n",
    "    mm9_lab = np.load(f'../data/VISTA/mm9/datasets/mm9.balanced.VISTA'\n",
    "                       f'.onehot.1000bp.{s}_y.npy', mmap_mode='r')\n",
    "\n",
    "    both_dat = np.vstack((hg19_dat, mm9_dat))\n",
    "    both_lab = np.hstack((hg19_lab, mm9_lab))\n",
    "\n",
    "    np.save(f'../data/VISTA/hg19.mm9.balanced.VISTA.onehot.1000bp.{s}_X'\n",
    "            f'.npy', both_dat)\n",
    "    np.save(f'../data/VISTA/hg19.mm9.balanced.VISTA.onehot.1000bp.{s}_y'\n",
    "            f'.npy', both_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping hg19 for the train split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:31<01:02, 31.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping hg19 for the val split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:39<00:17, 17.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping hg19 for the test split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:44<00:00, 14.74s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping mm9 for the train split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:19<00:39, 19.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping mm9 for the val split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:25<00:11, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping mm9 for the test split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished cropping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "species = ['hg19', 'mm9']\n",
    "split = ['train', 'val', 'test']\n",
    "\n",
    "for sp in species:\n",
    "    for s in tqdm(split):\n",
    "        print(f'Cropping {sp} for the {s} split.')\n",
    "        arr = np.load(f'../data/Fantom5/enhancer/{sp}/datasets/{sp}.balanced'\n",
    "                      f'.Fantom5.seq2img.2000bp.{s}_X.npy',\n",
    "                      mmap_mode='r')\n",
    "        arr_crop = arr[:, :, :32]\n",
    "\n",
    "        np.save(f'../data/Fantom5/enhancer/{sp}/datasets/{sp}.balanced.Fantom5'\n",
    "                f'.seq2img'\n",
    "                f'.cropped'\n",
    "        f'.2000bp.{s}_X.npy', arr_crop)\n",
    "print('Finished cropping')\n",
    "#print(arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:10<00:00,  3.58s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "split = ['train', 'val', 'test']\n",
    "\n",
    "for s in tqdm(split):\n",
    "    hg19_X = np.load(f'../data/Fantom5/enhancer/hg19/datasets/hg19.balanced'\n",
    "                     f'.Fantom5.seq2img.cropped.2000bp.{s}_X.npy',\n",
    "                     mmap_mode='r')\n",
    "    hg19_y = np.load(f'../data/Fantom5/enhancer/hg19/datasets/hg19.balanced'\n",
    "                     f'.Fantom5.seq2img.2000bp.{s}_y.npy',\n",
    "                     mmap_mode='r')\n",
    "    mm9_X = np.load(f'../data/Fantom5/enhancer/mm9/datasets/mm9.balanced'\n",
    "                    f'.Fantom5.seq2img.cropped.2000bp.{s}_X.npy',\n",
    "                    mmap_mode='r')\n",
    "    mm9_y = np.load(f'../data/Fantom5/enhancer/mm9/datasets/mm9.balanced'\n",
    "                    f'.Fantom5.seq2img.2000bp.{s}_y.npy',\n",
    "                    mmap_mode='r')\n",
    "\n",
    "    both_X = np.vstack((hg19_X, mm9_X))\n",
    "    both_y = np.hstack((hg19_y, mm9_y))\n",
    "\n",
    "    np.save(f'../data/Fantom5/enhancer/hg19.mm9.balanced.Fantom5.seq2img.2000bp'\n",
    "            f'.{s}_X.npy', both_X)\n",
    "    np.save(f'../data/Fantom5/enhancer/hg19.mm9.balanced.Fantom5.seq2img.2000bp'\n",
    "            f'.{s}_y.npy', both_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}